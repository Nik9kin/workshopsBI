{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8fb75c1",
   "metadata": {},
   "source": [
    "# Project 5. H+, or how to build a perfect human.\n",
    "\n",
    "Lab notebook by Nikita Vyatkin and Asya Bukreeva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06e3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984c1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_file_content(path, lines=10, headers_only=False):\n",
    "    if headers_only:\n",
    "        ! mkdir -p temp\n",
    "        ! touch temp/show_file_content.tmp\n",
    "        ! grep '>' {path} > temp/show_file_content.tmp\n",
    "        path = \"temp/show_file_content.tmp\"\n",
    "    \n",
    "    ! head -{lines} {path}\n",
    "    print(\"...\")\n",
    "    ! tail -{lines} {path}\n",
    "    \n",
    "    if headers_only:\n",
    "        ! rm {path}\n",
    "\n",
    "\n",
    "def count_seqs(path):\n",
    "    res = ! grep '>' {path} | wc -l\n",
    "    print(f\"Total: {res[0]} sequencies\")\n",
    "\n",
    "def find_snps_by_rsid(file_name, rsids):\n",
    "    for rsid in rsids:\n",
    "        ! grep {rsid} {file_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b748b",
   "metadata": {},
   "source": [
    "## Data source\n",
    "\n",
    "We will work with raw 23andMe data from the “GitHub Guy” (https://github.com/msporny/dna): released under Creative Commons Public Domain License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a139c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 39M\r\n",
      "-rw-rw-r-- 1 nikitos nikitos 24M фев 12 15:48 ManuSporny-genome.txt\r\n",
      "-rw-rw-r-- 1 nikitos nikitos 15M мар 24  2020 MikeRaiko-genome.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lh raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7699262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This data file generated by 23andMe at: Sat Feb 12 07:54:57 2011\n",
      "#\n",
      "# Below is a text version of your data. Fields are TAB-separated\n",
      "# Each line corresponds to a single SNP.  For each SNP, we provide its identifier \n",
      "# (an rsid or an internal id), its location on the reference human genome, and the \n",
      "# genotype call oriented with respect to the plus strand on the human reference \n",
      "# sequence.     We are using reference human assembly build 36.  Note that it is possible \n",
      "# that data downloaded at different times may be different due to ongoing improvements \n",
      "# in our ability to call genotypes. More information about these changes can be found at:\n",
      "# https://www.23andme.com/you/download/revisions/\n",
      "# \n",
      "# More information on reference human assembly build 36:\n",
      "# http://www.ncbi.nlm.nih.gov/projects/mapview/map_search.cgi?taxid=9606&build=36\n",
      "#\n",
      "# rsid\tchromosome\tposition\tgenotype\n",
      "rs4477212\t1\t72017\tAA\n",
      "rs3094315\t1\t742429\tAA\n",
      "rs3131972\t1\t742584\tGG\n",
      "rs12124819\t1\t766409\tAA\n",
      "rs11240777\t1\t788822\tAG\n",
      "...\n",
      "i3001917\tMT\t16460\t--\n",
      "i3001918\tMT\t16465\tA\n",
      "i3001919\tMT\t16467\tC\n",
      "i4000619\tMT\t16470\tT\n",
      "i3001920\tMT\t16472\tG\n",
      "i3001921\tMT\t16473\tG\n",
      "i3001925\tMT\t16484\tA\n",
      "i3001926\tMT\t16485\tG\n",
      "i4000691\tMT\t16490\tC\n",
      "i3001927\tMT\t16499\tA\n",
      "i4000690\tMT\t16520\tG\n",
      "rs3937033\tMT\t16521\tC\n",
      "i3001542\tMT\t16522\tC\n",
      "i4000692\tMT\t16526\tA\n",
      "i4000693\tMT\t16526\tA\n",
      "i4000757\tMT\t16528\tG\n",
      "i4990307\tMT\t16529\tC\n",
      "i4000756\tMT\t16542\tC\n",
      "i4000755\tMT\t16550\tC\n",
      "i4000759\tMT\t16569\tA\n"
     ]
    }
   ],
   "source": [
    "show_file_content(\"raw_data/ManuSporny-genome.txt\", lines=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe6abf",
   "metadata": {},
   "source": [
    "## File conversion\n",
    "\n",
    "For analysis we will need to convert 23andMe's raw data into standard vcf format. We will use [plink](https://www.cog-genomics.org/plink/), a program widely used in population genetics. One can download plink [here](https://www.cog-genomics.org/plink/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e03f7bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\r\n",
      "(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\r\n",
      "\r\n",
      "  plink <input flag(s)...> [command flag(s)...] [other flag(s)...]\r\n",
      "  plink --help [flag name(s)...]\r\n",
      "\r\n",
      "Commands include --make-bed, --recode, --flip-scan, --merge-list,\r\n",
      "--write-snplist, --list-duplicate-vars, --freqx, --missing, --test-mishap,\r\n",
      "--hardy, --mendel, --ibc, --impute-sex, --indep-pairphase, --r2, --show-tags,\r\n",
      "--blocks, --distance, --genome, --homozyg, --make-rel, --make-grm-gz,\r\n",
      "--rel-cutoff, --cluster, --pca, --neighbour, --ibs-test, --regress-distance,\r\n",
      "--model, --bd, --gxe, --logistic, --dosage, --lasso, --test-missing,\r\n",
      "--make-perm-pheno, --tdt, --qfam, --annotate, --clump, --gene-report,\r\n",
      "--meta-analysis, --epistasis, --fast-epistasis, and --score.\r\n",
      "\r\n",
      "\"plink --help | more\" describes all functions (warning: long).\r\n"
     ]
    }
   ],
   "source": [
    "! plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f73f9786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\r\n",
      "(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\r\n",
      "\r\n",
      "In the command line flag definitions that follow,\r\n",
      "  * <angle brackets> denote a required parameter, where the text between the\r\n",
      "    angle brackets describes its nature.\r\n",
      "  * ['square brackets + single-quotes'] denotes an optional modifier.  Use the\r\n",
      "    EXACT text in the quotes.\r\n",
      "  * [{bar|separated|braced|bracketed|values}] denotes a collection of mutually\r\n",
      "    exclusive optional modifiers (again, the exact text must be used).  When\r\n",
      "    there are no outer square brackets, one of the choices must be selected.\r\n",
      "  * ['quoted_text='<description of value>] denotes an optional modifier that\r\n",
      "    must begin with the quoted text, and be followed by a value with no\r\n",
      "    whitespace in between.  '|' may also be used here to indicate mutually\r\n",
      "    exclusive options.\r\n",
      "  * [square brackets without quotes or braces] denote an optional parameter,\r\n",
      "    where the text between the brackets describes its nature.\r\n",
      "  * An ellipsis (...) indicates that you may enter multiple parameters of the\r\n",
      "    specified type.\r\n",
      "\r\n",
      "  plink <input flag(s)...> [command flag(s)...] [other flag(s)...]\r\n",
      "  plink --help [flag name(s)...]\r\n",
      "\r\n",
      "Most PLINK runs require exactly one main input fileset.  The following flags\r\n",
      "are available for defining its form and location:\r\n",
      "\r\n",
      "  --bfile [prefix] : Specify .bed + .bim + .fam prefix (default 'plink').\r\n",
      "  --bed <filename> : Specify full name of .bed file.\r\n",
      "  --bim <filename> : Specify full name of .bim file.\r\n",
      "  --fam <filename> : Specify full name of .fam file.\r\n",
      "\r\n",
      "  --keep-autoconv  : With --file/--tfile/--lfile/--vcf/--bcf/--data/--23file,\r\n",
      "                     don't delete autogenerated binary fileset at end of run.\r\n",
      "\r\n",
      "  --file [prefix]  : Specify .ped + .map filename prefix (default 'plink').\r\n",
      "  --ped <filename> : Specify full name of .ped file.\r\n",
      "  --map <filename> : Specify full name of .map file.\r\n",
      "\r\n",
      "  --no-fid         : .fam/.ped file does not contain column 1 (family ID).\r\n",
      "  --no-parents     : .fam/.ped file does not contain columns 3-4 (parents).\r\n",
      "  --no-sex         : .fam/.ped file does not contain column 5 (sex).\r\n",
      "  --no-pheno       : .fam/.ped file does not contain column 6 (phenotype).\r\n",
      "\r\n",
      "  --tfile [prefix] : Specify .tped + .tfam filename prefix (default 'plink').\r\n",
      "  --tped <fname>   : Specify full name of .tped file.\r\n",
      "  --tfam <fname>   : Specify full name of .tfam file.\r\n",
      "\r\n",
      "  --lfile [prefix] : Specify .lgen + .map + .fam (long-format fileset) prefix.\r\n",
      "  --lgen <fname>   : Specify full name of .lgen file.\r\n",
      "  --reference <fn> : Specify default allele file accompanying .lgen input.\r\n",
      "  --allele-count   : When used with --lfile/--lgen + --reference, specifies\r\n",
      "                     that the .lgen file contains reference allele counts.\r\n",
      "\r\n",
      "  --vcf <filename> : Specify full name of .vcf or .vcf.gz file.\r\n",
      "  --bcf <filename> : Specify full name of BCF2 file.\r\n",
      "\r\n",
      "  --data [prefix]  : Specify Oxford .gen + .sample prefix (default 'plink').\r\n",
      "  --gen <filename> : Specify full name of .gen or .gen.gz file.\r\n",
      "  --bgen <f> ['snpid-chr'] : Specify full name of .bgen file.\r\n",
      "  --sample <fname> : Specify full name of .sample file.\r\n",
      "\r\n",
      "  --23file <fname> [FID] [IID] [sex] [pheno] [pat. ID] [mat. ID] :\r\n",
      "    Specify 23andMe input file.\r\n",
      "\r\n",
      "  --grm-gz [prfx]  : Specify .grm.gz + .grm.id (GCTA rel. matrix) prefix.\r\n",
      "  --grm-bin [prfx] : Specify .grm.bin + .grm.N.bin + .grm.id (GCTA triangular\r\n",
      "                     binary relationship matrix) filename prefix.\r\n",
      "\r\n",
      "  --dummy <sample ct> <SNP ct> [missing geno freq] [missing pheno freq]\r\n",
      "          [{acgt | 1234 | 12}] ['scalar-pheno']\r\n",
      "    This generates a fake input dataset with the specified number of samples\r\n",
      "    and SNPs.  By default, the missing genotype and phenotype frequencies are\r\n",
      "    zero, and genotypes are As and Bs (change the latter with\r\n",
      "    'acgt'/'1234'/'12').  The 'scalar-pheno' modifier causes a normally\r\n",
      "    distributed scalar phenotype to be generated instead of a binary one.\r\n",
      "\r\n",
      "  --simulate <simulation parameter file> [{tags | haps}] [{acgt | 1234 | 12}]\r\n",
      "  --simulate-qt <sim. parameter file> [{tags | haps}] [{acgt | 1234 | 12}]\r\n",
      "    --simulate generates a fake input dataset with disease-associated SNPs,\r\n",
      "    while --simulate-qt generates a dataset with quantitative trait loci.\r\n",
      "\r\n",
      "Output files have names of the form 'plink.<extension>' by default.  You can\r\n",
      "change the 'plink' prefix with\r\n",
      "\r\n",
      "  --out <prefix>   : Specify prefix for output files.\r\n",
      "\r\n",
      "Most runs also require at least one of the following commands:\r\n",
      "\r\n",
      "  --make-bed\r\n",
      "    Create a new binary fileset.  Unlike the automatic text-to-binary\r\n",
      "    converters (which only heed chromosome filters), this supports all of\r\n",
      "    PLINK's filtering flags.\r\n",
      "  --make-just-bim\r\n",
      "  --make-just-fam\r\n",
      "    Variants of --make-bed which only write a new .bim or .fam file.  Can be\r\n",
      "    used with only .bim/.fam input.\r\n",
      "    USE THESE CAUTIOUSLY.  It is very easy to desynchronize your binary\r\n",
      "    genotype data and your .bim/.fam indexes if you use these commands\r\n",
      "    improperly.  If you have any doubt, stick with --make-bed.\r\n",
      "\r\n",
      "  --recode <output format> [{01 | 12}] [{tab | tabx | spacex | bgz | gen-gz}]\r\n",
      "           ['include-alt'] ['omit-nonmale-y']\r\n",
      "    Create a new text fileset with all filters applied.  The following output\r\n",
      "    formats are supported:\r\n",
      "    * '23': 23andMe 4-column format.  This can only be used on a single\r\n",
      "      sample's data (--keep may be handy), and does not support multicharacter\r\n",
      "      allele codes.\r\n",
      "    * 'A': Sample-major additive (0/1/2) coding, suitable for loading from R.\r\n",
      "      If you need uncounted alleles to be named in the header line, add the\r\n",
      "      'include-alt' modifier.\r\n",
      "    * 'AD': Sample-major additive (0/1/2) + dominant (het=1/hom=0) coding.\r\n",
      "      Also supports 'include-alt'.\r\n",
      "    * 'A-transpose': Variant-major 0/1/2.\r\n",
      "    * 'beagle': Unphased per-autosome .dat and .map files, readable by early\r\n",
      "      BEAGLE versions.\r\n",
      "    * 'beagle-nomap': Single .beagle.dat file.\r\n",
      "    * 'bimbam': Regular BIMBAM format.\r\n",
      "    * 'bimbam-1chr': BIMBAM format, with a two-column .pos.txt file.  Does not\r\n",
      "      support multiple chromosomes.\r\n",
      "    * 'fastphase': Per-chromosome fastPHASE files, with\r\n",
      "      .chr-<chr #>.recode.phase.inp filename extensions.\r\n",
      "    * 'fastphase-1chr': Single .recode.phase.inp file.  Does not support\r\n",
      "      multiple chromosomes.\r\n",
      "    * 'HV': Per-chromosome Haploview files, with .chr-<chr #>{.ped,.info}\r\n",
      "      filename extensions.\r\n",
      "    * 'HV-1chr': Single Haploview .ped + .info file pair.  Does not support\r\n",
      "      multiple chromosomes.\r\n",
      "    * 'lgen': PLINK 1 long-format (.lgen + .fam + .map), loadable with --lfile.\r\n",
      "    * 'lgen-ref': .lgen + .fam + .map + .ref, loadable with --lfile +\r\n",
      "       --reference.\r\n",
      "    * 'list': Single genotype-based list, up to 4 lines per variant.  To omit\r\n",
      "      nonmale genotypes on the Y chromosome, add the 'omit-nonmale-y' modifier.\r\n",
      "    * 'rlist': .rlist + .fam + .map fileset, where the .rlist file is a\r\n",
      "      genotype-based list which omits the most common genotype for each\r\n",
      "      variant.  Also supports 'omit-nonmale-y'.\r\n",
      "    * 'oxford': Oxford-format .gen + .sample.  With the 'gen-gz' modifier, the\r\n",
      "      .gen file is gzipped.\r\n",
      "    * 'ped': PLINK 1 sample-major (.ped + .map), loadable with --file.\r\n",
      "    * 'compound-genotypes': Same as 'ped', except that the space between each\r\n",
      "      pair of same-variant allele codes is removed.\r\n",
      "    * 'structure': Structure-format.\r\n",
      "    * 'transpose': PLINK 1 variant-major (.tped + .tfam), loadable with\r\n",
      "      --tfile.\r\n",
      "    * 'vcf', 'vcf-fid', 'vcf-iid': VCFv4.2.  'vcf-fid' and 'vcf-iid' cause\r\n",
      "      family IDs or within-family IDs respectively to be used for the sample\r\n",
      "      IDs in the last header row, while 'vcf' merges both IDs and puts an\r\n",
      "      underscore between them.  If the 'bgz' modifier is added, the VCF file is\r\n",
      "      block-gzipped.\r\n",
      "      The A2 allele is saved as the reference and normally flagged as not based\r\n",
      "      on a real reference genome (INFO:PR).  When it is important for reference\r\n",
      "      alleles to be correct, you'll also want to include --a2-allele and\r\n",
      "      --real-ref-alleles in your command.\r\n",
      "    In addition,\r\n",
      "    * The '12' modifier causes A1 (usually minor) alleles to be coded as '1'\r\n",
      "      and A2 alleles to be coded as '2', while '01' maps A1 -> 0 and A2 -> 1.\r\n",
      "    * The 'tab' modifier makes the output mostly tab-delimited instead of\r\n",
      "      mostly space-delimited.  'tabx' and 'spacex' force all tabs and all\r\n",
      "      spaces, respectively.\r\n",
      "\r\n",
      "  --flip-scan ['verbose']\r\n",
      "    (alias: --flipscan)\r\n",
      "    LD-based scan for case/control strand inconsistency.\r\n",
      "\r\n",
      "  --write-covar\r\n",
      "    If a --covar file is loaded, --make-bed/--make-just-fam and --recode\r\n",
      "    automatically generate an updated version (with all filters applied).\r\n",
      "    However, if you do not wish to simultaneously generate a new genotype file,\r\n",
      "    you can use --write-covar to just produce a pruned covariate file.\r\n",
      "\r\n",
      "  --write-cluster ['omit-unassigned']\r\n",
      "    If clusters are specified with --within/--family, this generates a new\r\n",
      "    cluster file (with all filters applied).  The 'omit-unassigned' modifier\r\n",
      "    causes unclustered samples to be omitted from the file; otherwise their\r\n",
      "    cluster is 'NA'.\r\n",
      "\r\n",
      "  --write-set\r\n",
      "  --set-table\r\n",
      "    If sets have been defined, --write-set dumps 'END'-terminated set\r\n",
      "    membership lists to <output prefix>.set, while --set-table writes a\r\n",
      "    variant-by-set membership table to <output prefix>.set.table.\r\n",
      "\r\n",
      "  --merge <.ped filename> <.map filename>\r\n",
      "  --merge <text fileset prefix>\r\n",
      "  --bmerge <.bed filename> <.bim filename> <.fam filename>\r\n",
      "  --bmerge <binary fileset prefix>\r\n",
      "    Merge the given fileset with the initially loaded fileset, writing the\r\n",
      "    result to <output prefix>.bed + .bim + .fam.  (It is no longer necessary to\r\n",
      "    simultaneously specify --make-bed.)\r\n",
      "  --merge-list <filename>\r\n",
      "    Merge all filesets named in the text file with the reference fileset, if\r\n",
      "    one was specified.  (However, this can also be used *without* a reference;\r\n",
      "    in that case, the newly created fileset is then treated as the reference by\r\n",
      "    most other PLINK operations.)  The text file is interpreted as follows:\r\n",
      "    * If a line contains only one name, it is assumed to be the prefix for a\r\n",
      "      binary fileset.\r\n",
      "    * If a line contains exactly two names, they are assumed to be the full\r\n",
      "      filenames for a text fileset (.ped first, then .map).\r\n",
      "    * If a line contains exactly three names, they are assumed to be the full\r\n",
      "      filenames for a binary fileset (.bed, then .bim, then .fam).\r\n",
      "\r\n",
      "  --write-snplist\r\n",
      "  --list-23-indels\r\n",
      "    --write-snplist writes a .snplist file listing the names of all variants\r\n",
      "    which pass the filters and inclusion thresholds you've specified, while\r\n",
      "    --list-23-indels writes the subset with 23andMe-style indel calls (D/I\r\n",
      "    allele codes).\r\n",
      "\r\n",
      "  --list-duplicate-vars ['require-same-ref'] ['ids-only'] ['suppress-first']\r\n",
      "    --list-duplicate-vars writes a .dupvar file describing all groups of\r\n",
      "    variants with matching positions and allele codes.\r\n",
      "    * By default, A1/A2 allele assignments are ignored; use 'require-same-ref'\r\n",
      "      to override this.\r\n",
      "    * Normally, the report contains position and allele codes.  To remove them\r\n",
      "      (and produce a file directly usable with e.g. --extract/--exclude), use\r\n",
      "      'ids-only'.  Note that this command will fail in 'ids-only' mode if any\r\n",
      "      of the reported IDs are not unique.\r\n",
      "    * 'suppress-first' causes the first variant ID in each group to be omitted\r\n",
      "      from the report.\r\n",
      "\r\n",
      "  --freq [{counts | case-control}] ['gz']\r\n",
      "  --freqx ['gz']\r\n",
      "    --freq generates a basic allele frequency (or count, if the 'counts'\r\n",
      "    modifier is present) report.  This can be combined with --within/--family\r\n",
      "    to produce a cluster-stratified allele frequency/count report instead, or\r\n",
      "    the 'case-control' modifier to report case and control allele frequencies\r\n",
      "    separately.\r\n",
      "    --freqx generates a more detailed genotype count report, designed for use\r\n",
      "    with --read-freq.\r\n",
      "\r\n",
      "  --missing ['gz']\r\n",
      "    Generate sample- and variant-based missing data reports.  If clusters are\r\n",
      "    defined, the variant-based report is cluster-stratified.  'gz' causes the\r\n",
      "    output files to be gzipped.\r\n",
      "    Unlike most other commands, this doesn't treat het. haploids as missing.\r\n",
      "\r\n",
      "  --test-mishap\r\n",
      "    Check for association between missing calls and flanking haplotypes.\r\n",
      "\r\n",
      "  --hardy ['midp'] ['gz']\r\n",
      "    Generate a Hardy-Weinberg exact test p-value report.  (This does NOT\r\n",
      "    simultaneously filter on the p-value any more; use --hwe for that.)  With\r\n",
      "    the 'midp' modifier, the test applies the mid-p adjustment described in\r\n",
      "    Graffelman J, Moreno V (2013) The mid p-value in exact tests for\r\n",
      "    Hardy-Weinberg Equilibrium.\r\n",
      "\r\n",
      "  --mendel ['summaries-only']\r\n",
      "    Generate a Mendel error report.  The 'summaries-only' modifier causes the\r\n",
      "    .mendel file (listing every single error) to be skipped.\r\n",
      "\r\n",
      "  --het ['small-sample'] ['gz']\r\n",
      "  --ibc\r\n",
      "    Estimate inbreeding coefficients.  --het reports method-of-moments\r\n",
      "    estimates, while --ibc calculates all three values described in Yang J, Lee\r\n",
      "    SH, Goddard ME and Visscher PM (2011) GCTA: A Tool for Genome-wide Complex\r\n",
      "    Trait Analysis.  (That paper also describes the relationship matrix\r\n",
      "    computation we reimplement.)\r\n",
      "    * These functions require decent MAF estimates.  If there are very few\r\n",
      "      samples in your immediate fileset, --read-freq is practically mandatory\r\n",
      "      since imputed MAFs are wildly inaccurate in that case.\r\n",
      "    * They also assume the marker set is in approximate linkage equilibrium.\r\n",
      "    * By default, --het omits the n/(n-1) multiplier in Nei's expected\r\n",
      "      homozygosity formula.  The 'small-sample' modifier causes it to be\r\n",
      "      included, while forcing --het to use MAFs imputed from founders in the\r\n",
      "      immediate dataset.\r\n",
      "\r\n",
      "  --check-sex [female max F] [male min F]\r\n",
      "  --check-sex ycount [female max F] [male min F] [female max Y obs]\r\n",
      "                     [male min Y obs]\r\n",
      "  --check-sex y-only [female max Y obs] [male min Y obs]\r\n",
      "  --impute-sex [female max F] [male min F]\r\n",
      "  --impute-sex ycount [female max F] [male min F] [female max Y obs]\r\n",
      "                      [male min Y obs]\r\n",
      "  --impute-sex y-only [female max Y obs] [male min Y obs]\r\n",
      "    --check-sex normally compares sex assignments in the input dataset with\r\n",
      "    those imputed from X chromosome inbreeding coefficients.\r\n",
      "    * Make sure that the X chromosome pseudo-autosomal region has been split\r\n",
      "      off (with e.g. --split-x) before using this.\r\n",
      "    * You also need decent MAF estimates (so, with very few samples in your\r\n",
      "      immediate fileset, use --read-freq), and your marker set should be in\r\n",
      "      approximate linkage equilibrium.\r\n",
      "    * By default, F estimates smaller than 0.2 yield female calls, and values\r\n",
      "      larger than 0.8 yield male calls.  If you pass numeric parameter(s) to\r\n",
      "      --check-sex, the first two control these thresholds.\r\n",
      "    There are now two modes which consider Y chromosome data.\r\n",
      "    * In 'ycount' mode, gender is still imputed from the X chromosome, but\r\n",
      "      female calls are downgraded to ambiguous whenever more than 0 nonmissing\r\n",
      "      Y genotypes are present, and male calls are downgraded when fewer than 0\r\n",
      "      are present.  (Note that these are counts, not rates.)  These thresholds\r\n",
      "      are controllable with --check-sex ycount's optional 3rd and 4th numeric\r\n",
      "      parameters.\r\n",
      "    * In 'y-only' mode, gender is imputed from nonmissing Y genotype counts.\r\n",
      "      The male minimum threshold defaults to 1 instead of zero in this case.\r\n",
      "    --impute-sex changes sex assignments to the imputed values, and is\r\n",
      "    otherwise identical to --check-sex.  It must be used with\r\n",
      "    --make-bed/--recode/--write-covar.\r\n",
      "\r\n",
      "  --fst ['case-control']\r\n",
      "    (alias: --Fst)\r\n",
      "    Estimate Wright's Fst for each autosomal diploid variant using the method\r\n",
      "    introduced in Weir BS, Cockerham CC (1984) Estimating F-statistics for the\r\n",
      "    analysis of population structure, given a set of subpopulations defined via\r\n",
      "    --within.  Raw and weighted global means are also reported.\r\n",
      "    * If you're interested in the global means, it is usually best to perform\r\n",
      "      this calculation on a marker set in approximate linkage equilibrium.\r\n",
      "    * If you have only two subpopulations, you can represent them with\r\n",
      "      case/control status and use the 'case-control' modifier.\r\n",
      "\r\n",
      "  --indep <window size>['kb'] <step size (variant ct)> <VIF threshold>\r\n",
      "  --indep-pairwise <window size>['kb'] <step size (variant ct)> <r^2 threshold>\r\n",
      "  --indep-pairphase <window size>['kb'] <step size (variant ct)> <r^2 thresh>\r\n",
      "    Generate a list of markers in approximate linkage equilibrium.  With the\r\n",
      "    'kb' modifier, the window size is in kilobase instead of variant count\r\n",
      "    units.  (Pre-'kb' space is optional, i.e. \"--indep-pairwise 500 kb 5 0.5\"\r\n",
      "    and \"--indep-pairwise 500kb 5 0.5\" have the same effect.)\r\n",
      "    Note that you need to rerun PLINK using --extract or --exclude on the\r\n",
      "    .prune.in/.prune.out file to apply the list to another computation.\r\n",
      "\r\n",
      "  --r [{square | square0 | triangle | inter-chr}] [{gz | bin | bin4}]\r\n",
      "      ['spaces'] ['in-phase'] [{d | dprime | dprime-signed}] ['with-freqs']\r\n",
      "      ['yes-really']\r\n",
      "  --r2 [{square | square0 | triangle | inter-chr}] [{gz | bin | bin4}]\r\n",
      "       ['spaces'] ['in-phase'] [{d | dprime | dprime-signed}] ['with-freqs']\r\n",
      "       ['yes-really']\r\n",
      "    LD statistic reports.  --r yields raw inter-variant correlations, while\r\n",
      "    --r2 reports their squares.  You can request results for all pairs in\r\n",
      "    matrix format (if you specify 'bin' or one of the shape modifiers), all\r\n",
      "    pairs in table format ('inter-chr'), or a limited window in table format\r\n",
      "    (default).\r\n",
      "    * The 'gz' modifier causes the output text file to be gzipped.\r\n",
      "    * 'bin' causes the output matrix to be written in double-precision binary\r\n",
      "      format, while 'bin4' specifics single-precision binary.  The matrix is\r\n",
      "      square if no shape is explicitly specified.\r\n",
      "    * By default, text matrices are tab-delimited; 'spaces' switches this.\r\n",
      "    * 'in-phase' adds a column with in-phase allele pairs to table-formatted\r\n",
      "      reports.  (This cannot be used with very long allele codes.)\r\n",
      "    * 'dprime' adds the absolute value of Lewontin's D-prime statistic to\r\n",
      "      table-formatted reports, and forces both r/r^2 and D-prime to be based on\r\n",
      "      the maximum likelihood solution to the cubic equation discussed in Gaunt\r\n",
      "      T, Rodriguez S, Day I (2007) Cubic exact solutions for the estimation of\r\n",
      "      pairwise haplotype frequencies.\r\n",
      "      'dprime-signed' keeps the sign, while 'd' skips division by D_{max}.\r\n",
      "    * 'with-freqs' adds MAF columns to table-formatted reports.\r\n",
      "    * Since the resulting file can easily be huge, you're required to add the\r\n",
      "      'yes-really' modifier when requesting an unfiltered, non-distributed all\r\n",
      "      pairs computation on more than 400k variants.\r\n",
      "    * These computations can be subdivided with --parallel (even when the\r\n",
      "      'square' modifier is active).\r\n",
      "  --ld <variant ID> <variant ID> ['hwe-midp']\r\n",
      "    This displays haplotype frequencies, r^2, and D' for a single pair of\r\n",
      "    variants.  When there are multiple biologically possible solutions to the\r\n",
      "    haplotype frequency cubic equation, all are displayed (instead of just the\r\n",
      "    maximum likelihood solution identified by --r/--r2), along with HWE exact\r\n",
      "    test statistics.\r\n",
      "\r\n",
      "  --show-tags <filename>\r\n",
      "  --show-tags all\r\n",
      "    * If a file is specified, list all variants which tag at least one variant\r\n",
      "      named in the file.  (This will normally be a superset of the original\r\n",
      "      list, since a variant is considered to tag itself here.)\r\n",
      "    * If 'all' mode is specified, for each variant, each *other* variant which\r\n",
      "      tags it is reported.\r\n",
      "\r\n",
      "  --blocks ['no-pheno-req'] ['no-small-max-span']\r\n",
      "    Estimate haplotype blocks, via Haploview's interpretation of the block\r\n",
      "    definition suggested by Gabriel S et al. (2002) The Structure of Haplotype\r\n",
      "    Blocks in the Human Genome.\r\n",
      "    * Normally, samples with missing phenotypes are not considered by this\r\n",
      "      computation; the 'no-pheno-req' modifier lifts this restriction.\r\n",
      "    * Normally, size-2 blocks may not span more than 20kb, and size-3 blocks\r\n",
      "      are limited to 30kb.  The 'no-small-max-span' modifier removes these\r\n",
      "      limits.\r\n",
      "    The .blocks file is valid input for PLINK 1.07's --hap command.  However,\r\n",
      "    the --hap... family of flags has not been reimplemented in PLINK 1.9 due to\r\n",
      "    poor phasing accuracy relative to other software; for now, we recommend\r\n",
      "    using BEAGLE instead of PLINK for case/control haplotype association\r\n",
      "    analysis.  (You can use \"--recode beagle\" to export data to BEAGLE 3.3.)\r\n",
      "    We apologize for the inconvenience, and plan to develop variants of the\r\n",
      "    --hap... flags which handle pre-phased data effectively.\r\n",
      "\r\n",
      "  --distance [{square | square0 | triangle}] [{gz | bin | bin4}] ['ibs']\r\n",
      "             ['1-ibs'] ['allele-ct'] ['flat-missing']\r\n",
      "    Write a lower-triangular tab-delimited table of (weighted) genomic\r\n",
      "    distances in allele count units to <output prefix>.dist, and a list of the\r\n",
      "    corresponding sample IDs to <output prefix>.dist.id.  The first row of the\r\n",
      "    .dist file contains a single <genome 1-genome 2> distance, the second row\r\n",
      "    has the <genome 1-genome 3> and <genome 2-genome 3> distances in that\r\n",
      "    order, etc.\r\n",
      "    * It is usually best to perform this calculation on a marker set in\r\n",
      "      approximate linkage equilibrium.\r\n",
      "    * If the 'square' or 'square0' modifier is present, a square matrix is\r\n",
      "      written instead; 'square0' fills the upper right triangle with zeroes.\r\n",
      "    * If the 'gz' modifier is present, a compressed .dist.gz file is written\r\n",
      "      instead of a plain text file.\r\n",
      "    * If the 'bin' modifier is present, a binary (square) matrix of\r\n",
      "      double-precision floating point values, suitable for loading from R, is\r\n",
      "      instead written to <output prefix>.dist.bin.  ('bin4' specifies\r\n",
      "      single-precision numbers instead.)  This can be combined with 'square0'\r\n",
      "      if you still want the upper right zeroed out, or 'triangle' if you don't\r\n",
      "      want to pad the upper right at all.\r\n",
      "    * If the 'ibs' modifier is present, an identity-by-state matrix is written\r\n",
      "      to <output prefix>.mibs.  '1-ibs' causes distances expressed as genomic\r\n",
      "      proportions (i.e. 1 - IBS) to be written to <output prefix>.mdist.\r\n",
      "      Combine with 'allele-ct' if you want to generate the usual .dist file as\r\n",
      "      well.\r\n",
      "    * By default, distance rescaling in the presence of missing genotype calls\r\n",
      "      is sensitive to allele count distributions: if variant A contributes, on\r\n",
      "      average, twice as much to other pairwise distances as variant B, a\r\n",
      "      missing call at variant A will result in twice as large of a missingness\r\n",
      "      correction.  To turn this off (because e.g. your missing calls are highly\r\n",
      "      nonrandom), use the 'flat-missing' modifier.\r\n",
      "    * The computation can be subdivided with --parallel.\r\n",
      "  --distance-matrix\r\n",
      "  --ibs-matrix\r\n",
      "    These deprecated commands are equivalent to \"--distance 1-ibs flat-missing\r\n",
      "    square\" and \"--distance ibs flat-missing square\", respectively, except that\r\n",
      "    they generate space- instead of tab-delimited text matrices.\r\n",
      "\r\n",
      "  --make-rel [{square | square0 | triangle}] [{gz | bin | bin4}]\r\n",
      "             [{cov | ibc2 | ibc3}]\r\n",
      "    Write a lower-triangular variance-standardized realized relationship matrix\r\n",
      "    to <output prefix>.rel, and corresponding IDs to <output prefix>.rel.id.\r\n",
      "    * It is usually best to perform this calculation on a marker set in\r\n",
      "      approximate linkage equilibrium.\r\n",
      "    * 'square', 'square0', 'triangle', 'gz', 'bin', and 'bin4' act as they do\r\n",
      "      on --distance.\r\n",
      "    * The 'cov' modifier removes the variance standardization step, causing a\r\n",
      "      covariance matrix to be calculated instead.\r\n",
      "    * By default, the diagonal elements in the relationship matrix are based on\r\n",
      "      --ibc's Fhat1; use the 'ibc2' or 'ibc3' modifiers to base them on Fhat2\r\n",
      "      or Fhat3 instead.\r\n",
      "    * The computation can be subdivided with --parallel.\r\n",
      "  --make-grm-gz ['no-gz'] [{cov | ibc2 | ibc3}]\r\n",
      "  --make-grm-bin [{cov | ibc2 | ibc3}]\r\n",
      "    --make-grm-gz writes the relationships in GCTA's original gzipped list\r\n",
      "    format, which describes one pair per line, while --make-grm-bin writes them\r\n",
      "    in GCTA 1.1+'s single-precision triangular binary format.  Note that these\r\n",
      "    formats explicitly report the number of valid observations (where neither\r\n",
      "    sample has a missing call) for each pair, which is useful input for some\r\n",
      "    scripts.\r\n",
      "    These computations can be subdivided with --parallel.\r\n",
      "\r\n",
      "  --rel-cutoff [val]\r\n",
      "    (alias: --grm-cutoff)\r\n",
      "    Exclude one member of each pair of samples with relatedness greater than\r\n",
      "    the given cutoff value (default 0.025).  If no later operation will cause\r\n",
      "    the list of remaining samples to be written to disk, this will save it to\r\n",
      "    <output prefix>.rel.id.\r\n",
      "    Note that maximizing the remaining sample size is equivalent to the NP-hard\r\n",
      "    maximum independent set problem, so we use a greedy algorithm instead of\r\n",
      "    guaranteeing optimality.  (Use the --make-rel and --keep/--remove flags if\r\n",
      "    you want to try to do better.)\r\n",
      "\r\n",
      "  --ibs-test [permutation count]\r\n",
      "  --groupdist [iters] [d]\r\n",
      "    Given case/control phenotype data, these commands consider three subsets of\r\n",
      "    the distance matrix: pairs of affected samples, affected-unaffected pairs,\r\n",
      "    and pairs of unaffected samples.  Each of these subsets has a distribution\r\n",
      "    of pairwise genomic distances; --ibs-test uses permutation to estimate\r\n",
      "    p-values re: which types of pairs are most similar, while --groupdist\r\n",
      "    focuses on the differences between the centers of these distributions and\r\n",
      "    estimates standard errors via delete-d jackknife.\r\n",
      "\r\n",
      "  --regress-distance [iters] [d]\r\n",
      "    Linear regression of pairwise genomic distances on pairwise average\r\n",
      "    phenotypes and vice versa, using delete-d jackknife for standard errors.  A\r\n",
      "    scalar phenotype is required.\r\n",
      "    * With less than two parameters, d is set to <number of people>^0.6 rounded\r\n",
      "      down.  With no parameters, 100k iterations are run.\r\n",
      "  --regress-rel [iters] [d]\r\n",
      "    Linear regression of pairwise genomic relationships on pairwise average\r\n",
      "    phenotypes, and vice versa.  Defaults for iters and d are the same as for\r\n",
      "    --regress-distance.\r\n",
      "\r\n",
      "  --genome ['gz'] ['rel-check'] ['full'] ['unbounded'] ['nudge']\r\n",
      "    Generate an identity-by-descent report.\r\n",
      "    * It is usually best to perform this calculation on a marker set in\r\n",
      "      approximate linkage equilibrium.\r\n",
      "    * The 'rel-check' modifier excludes pairs of samples with different FIDs\r\n",
      "      from the final report.\r\n",
      "    * 'full' adds raw pairwise comparison data to the report.\r\n",
      "    * The P(IBD=0/1/2) estimator employed by this command sometimes yields\r\n",
      "      numbers outside the range [0,1]; by default, these are clipped.  The\r\n",
      "      'unbounded' modifier turns off this clipping.\r\n",
      "    * Then, when PI_HAT^2 < P(IBD=2), 'nudge' adjusts the final P(IBD=0/1/2)\r\n",
      "      estimates to a theoretically possible configuration.\r\n",
      "    * The computation can be subdivided with --parallel.\r\n",
      "\r\n",
      "  --homozyg [{group | group-verbose}] ['consensus-match'] ['extend']\r\n",
      "            ['subtract-1-from-lengths']\r\n",
      "  --homozyg-snp <min var count>\r\n",
      "  --homozyg-kb <min length>\r\n",
      "  --homozyg-density <max inverse density (kb/var)>\r\n",
      "  --homozyg-gap <max internal gap kb length>\r\n",
      "  --homozyg-het <max hets>\r\n",
      "  --homozyg-window-snp <scanning window size>\r\n",
      "  --homozyg-window-het <max hets in scanning window hit>\r\n",
      "  --homozyg-window-missing <max missing calls in scanning window hit>\r\n",
      "  --homozyg-window-threshold <min scanning window hit rate>\r\n",
      "    These commands request a set of run-of-homozygosity reports, and allow you\r\n",
      "    to customize how they are generated.\r\n",
      "    * If you're satisfied with all the default settings described below, just\r\n",
      "      use --homozyg with no modifiers.  Otherwise, --homozyg lets you change a\r\n",
      "      few binary settings:\r\n",
      "      * 'group[-verbose]' adds a report on pools of overlapping runs of\r\n",
      "        homozygosity.  (Automatically set when --homozyg-match is present.)\r\n",
      "      * With 'group[-verbose]', 'consensus-match' causes pairwise segmental\r\n",
      "        matches to be called based on the variants in the pool's consensus\r\n",
      "        segment, rather than the variants in the pairwise intersection.\r\n",
      "      * Due to how the scanning window algorithm works, it is possible for a\r\n",
      "        reported ROH to be adjacent to a few homozygous variants.  The 'extend'\r\n",
      "        modifier causes them to be included in the reported ROH if that\r\n",
      "        wouldn't cause a violation of the --homozyg-density bound.\r\n",
      "      * By default, segment bp lengths are calculated as <end bp position> -\r\n",
      "        <start bp position> + 1.  Therefore, reports normally differ slightly\r\n",
      "        from PLINK 1.07, which does not add 1 at the end.  For testing\r\n",
      "        purposes, you can use the 'subtract-1-from-lengths' modifier to apply\r\n",
      "        the old formula.\r\n",
      "    * By default, only runs of homozygosity containing at least 100 variants,\r\n",
      "      and of total length >= 1000 kilobases, are noted.  You can change these\r\n",
      "      minimums with --homozyg-snp and --homozyg-kb, respectively.\r\n",
      "    * By default, a ROH must have at least one variant per 50 kb on average;\r\n",
      "      change this bound with --homozyg-density.\r\n",
      "    * By default, if two consecutive variants are more than 1000 kb apart, they\r\n",
      "      cannot be in the same ROH; change this bound with --homozyg-gap.\r\n",
      "    * By default, a ROH can contain an unlimited number of heterozygous calls;\r\n",
      "      you can impose a limit with --homozyg-het.\r\n",
      "    * By default, the scanning window contains 50 variants; change this with\r\n",
      "      --homozyg-window-snp.\r\n",
      "    * By default, a scanning window hit can contain at most 1 heterozygous\r\n",
      "      call and 5 missing calls; change these limits with --homozyg-window-het\r\n",
      "      and --homozyg-window-missing, respectively.\r\n",
      "    * By default, for a variant to be eligible for inclusion in a ROH, the hit\r\n",
      "      rate of all scanning windows containing the variant must be at least\r\n",
      "      0.05; change this threshold with --homozyg-window-threshold.\r\n",
      "\r\n",
      "  --cluster ['cc'] [{group-avg | old-tiebreaks}] ['missing'] ['only2']\r\n",
      "    Cluster samples using a pairwise similarity statistic (normally IBS).\r\n",
      "    * The 'cc' modifier forces every cluster to have at least one case and one\r\n",
      "      control.\r\n",
      "    * The 'group-avg' modifier causes clusters to be joined based on average\r\n",
      "      instead of minimum pairwise similarity.\r\n",
      "    * The 'missing' modifier causes clustering to be based on\r\n",
      "      identity-by-missingness instead of identity-by-state, and writes a\r\n",
      "      space-delimited identity-by-missingness matrix to disk.\r\n",
      "    * The 'only2' modifier causes only a .cluster2 file (which is valid input\r\n",
      "      for --within) to be written; otherwise 2 other files will be produced.\r\n",
      "    * By default, IBS ties are not broken in the same manner as PLINK 1.07, so\r\n",
      "      final cluster solutions tend to differ.  This is generally harmless.\r\n",
      "      However, to simplify testing, you can use the 'old-tiebreaks' modifier to\r\n",
      "      force emulation of the old algorithm.\r\n",
      "\r\n",
      "  --pca [count] ['header'] ['tabs'] ['var-wts']\r\n",
      "    Calculates a variance-standardized relationship matrix (use\r\n",
      "    --make-rel/--make-grm-gz/--make-grm-bin to dump it), and extracts the top\r\n",
      "    20 principal components.\r\n",
      "    * It is usually best to perform this calculation on a marker set in\r\n",
      "      approximate linkage equilibrium.\r\n",
      "    * You can change the number of PCs by passing a numeric parameter.\r\n",
      "    * The 'header' modifier adds a header line to the .eigenvec output file.\r\n",
      "      (For compatibility with the GCTA flag of the same name, the default is no\r\n",
      "      header line.)\r\n",
      "    * The 'tabs' modifier causes the .eigenvec file(s) to be tab-delimited.\r\n",
      "    * The 'var-wts' modifier requests an additional .eigenvec.var file with PCs\r\n",
      "      expressed as variant weights instead of sample weights.\r\n",
      "\r\n",
      "  --neighbour <n1> <n2>\r\n",
      "    (alias: --neighbor)\r\n",
      "    Report IBS distances from each sample to their n1th- to n2th-nearest\r\n",
      "    neighbors, associated Z-scores, and the identities of those neighbors.\r\n",
      "    Useful for outlier detection.\r\n",
      "\r\n",
      "  --assoc ['perm' | 'mperm='<value>] ['perm-count'] [{fisher | fisher-midp}]\r\n",
      "          ['counts'] ['set-test']\r\n",
      "  --assoc ['perm' | 'mperm='<value>] ['perm-count'] ['qt-means'] ['lin']\r\n",
      "          ['set-test']\r\n",
      "  --model ['perm' | 'mperm='<value>] ['perm-count']\r\n",
      "          [{fisher | fisher-midp | trend-only}] ['set-test']\r\n",
      "          [{dom | rec | gen | trend}]\r\n",
      "    Basic association analysis report.\r\n",
      "    Given a case/control phenotype, --assoc performs a 1df chi-square allelic\r\n",
      "    test, while --model performs 4 other tests as well (1df dominant gene\r\n",
      "    action, 1df recessive gene action, 2df genotypic, Cochran-Armitage trend).\r\n",
      "    * With 'fisher'/'fisher-midp', Fisher's exact test is used to generate\r\n",
      "      p-values.  'fisher-midp' also applies Lancaster's mid-p adjustment.\r\n",
      "    * 'perm' causes an adaptive permutation test to be performed.\r\n",
      "    * 'mperm='<value> causes a max(T) permutation test with the specified\r\n",
      "      number of replications to be performed.\r\n",
      "    * 'perm-count' causes the permutation test report to include counts instead\r\n",
      "      of frequencies.\r\n",
      "    * 'counts' causes --assoc to report allele counts instead of frequencies.\r\n",
      "    * 'set-test' tests the significance of variant sets.  Requires permutation;\r\n",
      "      can be customized with --set-p/--set-r2/--set-max.\r\n",
      "    * 'dom', 'rec', 'gen', and 'trend' force the corresponding test to be used\r\n",
      "      as the basis for --model permutation.  (By default, the most significant\r\n",
      "      result among the allelic, dominant, and recessive tests is used.)\r\n",
      "    * 'trend-only' causes only the trend test to be performed.\r\n",
      "    Given a quantitative phenotype, --assoc normally performs a Wald test.\r\n",
      "    * In this case, the 'qt-means' modifier causes trait means and standard\r\n",
      "      deviations stratified by genotype to be reported as well.\r\n",
      "    * 'lin' causes the Lin statistic to be computed, and makes it the basis for\r\n",
      "      multiple-testing corrections and permutation tests.\r\n",
      "    Several other flags (most notably, --aperm) can be used to customize the\r\n",
      "    permutation test.\r\n",
      "\r\n",
      "  --mh ['perm' | 'mperm='<value>] ['perm-count'] ['set-test']\r\n",
      "    (alias: --cmh)\r\n",
      "  --bd ['perm' | 'perm-bd' | 'mperm='<value>] ['perm-count'] ['set-test']\r\n",
      "  --mh2\r\n",
      "  --homog\r\n",
      "    Given a case/control phenotype and a set of clusters, --mh computes 2x2xK\r\n",
      "    Cochran-Mantel-Haenszel statistics for each variant, while --bd also\r\n",
      "    performs the Breslow-Day test for odds ratio homogeneity.  Permutation and\r\n",
      "    variant set testing based on the CMH (default) or Breslow-Day (when\r\n",
      "    'perm-bd' is present) statistic are supported.\r\n",
      "    The following similar analyses are also available:\r\n",
      "    * --mh2 swaps the roles of case/control status and cluster membership,\r\n",
      "      performing a phenotype-stratified IxJxK Cochran-Mantel-Haenszel test on\r\n",
      "      association between cluster assignments and genotypes.\r\n",
      "    * --homog executes an alternative to the Breslow-Day test, based on\r\n",
      "      partitioning of the chi-square statistic.\r\n",
      "\r\n",
      "  --gxe [covariate index]\r\n",
      "    Given both a quantitative phenotype and a case/control covariate loaded\r\n",
      "    with --covar defining two groups, --gxe compares the regression coefficient\r\n",
      "    derived from considering only members of one group to the regression\r\n",
      "    coefficient derived from considering only members of the other.  By\r\n",
      "    default, the first covariate in the --covar file defines the groups; use\r\n",
      "    e.g. \"--gxe 3\" to base them on the third covariate instead.\r\n",
      "\r\n",
      "  --linear ['perm' | 'mperm='<value>] ['perm-count'] ['set-test']\r\n",
      "           [{genotypic | hethom | dominant | recessive | no-snp}]\r\n",
      "           ['hide-covar'] [{sex | no-x-sex}] ['interaction'] ['beta']\r\n",
      "           ['standard-beta'] ['intercept']\r\n",
      "  --logistic ['perm' | 'mperm='<value>] ['perm-count'] ['set-test']\r\n",
      "             [{genotypic | hethom | dominant | recessive | no-snp}]\r\n",
      "             ['hide-covar'] [{sex | no-x-sex}] ['interaction'] ['beta']\r\n",
      "             ['intercept']\r\n",
      "    Multi-covariate association analysis on a quantitative (--linear) or\r\n",
      "    case/control (--logistic) phenotype.  Normally used with --covar.\r\n",
      "    * 'perm' normally causes an adaptive permutation test to be performed on\r\n",
      "      the main effect, while 'mperm='<value> starts a max(T) permutation test.\r\n",
      "    * 'perm-count' causes the permutation test report to include counts instead\r\n",
      "      of frequencies.\r\n",
      "    * 'set-test' tests the significance of variant sets.  Requires permutation;\r\n",
      "      can be customized with --set-p/--set-r2/--set-max.\r\n",
      "    * The 'genotypic' modifier adds an additive effect/dominance deviation 2df\r\n",
      "      joint test (0/1/2 and 0/1/0 coding), while 'hethom' uses 0/0/1 and 0/1/0\r\n",
      "      coding instead.  If permutation is also requested, these modifiers cause\r\n",
      "      permutation to be based on the joint test.\r\n",
      "    * 'dominant' and 'recessive' specify a model assuming full dominance or\r\n",
      "      recessiveness, respectively, for the A1 allele.\r\n",
      "    * 'no-snp' causes regression to be performed only on the phenotype and the\r\n",
      "      covariates, without reference to genomic data.  If permutation is also\r\n",
      "      requested, results are reported for all covariates.\r\n",
      "    * 'hide-covar' removes covariate-specific lines from the report.\r\n",
      "    * By default, sex (male = 1, female = 0) is automatically added as a\r\n",
      "      covariate on X chromosome variants, and nowhere else.  The 'sex' modifier\r\n",
      "      causes it to be added everywhere, while 'no-x-sex' excludes it.\r\n",
      "    * 'interaction' adds genotype x covariate interactions to the model.  This\r\n",
      "      cannot be used with the usual permutation tests; use --tests to define\r\n",
      "      the permutation test statistic instead.\r\n",
      "    * 'intercept' causes intercepts to be included in the main report.\r\n",
      "    * For logistic regressions, the 'beta' modifier causes regression\r\n",
      "      coefficients instead of odds ratios to be reported.\r\n",
      "    * With --linear, the 'standard-beta' modifier standardizes the phenotype\r\n",
      "      and all predictors to zero mean and unit variance before regression.\r\n",
      "\r\n",
      "  --dosage <allele dosage file> ['noheader'] ['skip0='<i>] ['skip1='<j>]\r\n",
      "           ['skip2='<k>] ['dose1'] ['format='<m>] ['Zout']\r\n",
      "           [{occur | standard-beta}] ['sex'] ['case-control-freqs']\r\n",
      "  --dosage <list file> list [{sepheader | noheader}] ['skip0='<i>]\r\n",
      "           ['skip1='<j>] ['skip2='<k>] ['dose1'] ['format='<m>] ['Zout']\r\n",
      "           [{occur | standard-beta}] ['sex'] ['case-control-freqs']\r\n",
      "  --write-dosage\r\n",
      "    Process (possibly gzipped) text files with variant-major allelic dosage\r\n",
      "    data.  This cannot be used with a regular input fileset; instead, you must\r\n",
      "    *only* specify a .fam and possibly a .map file, and you can't specify any\r\n",
      "    other commands.\r\n",
      "    * PLINK 2.0 will have first-class support for genotype probabilities.  An\r\n",
      "      equivalent data import flag will be provided then, and --dosage will be\r\n",
      "      retired.\r\n",
      "    * By default, --dosage assumes that only one allelic dosage file should be\r\n",
      "      loaded.  To specify multiple files,\r\n",
      "      1. create a master list with one entry per line.  There are normally two\r\n",
      "         supported formats for this list: just a filename per line, or variant\r\n",
      "         batch numbers in the first column and filenames in the second.\r\n",
      "      2. Provide the name of that list as the first --dosage parameter.\r\n",
      "      3. Add the 'list' modifier.\r\n",
      "    * By default, --dosage assumes the allelic dosage file(s) contain a header\r\n",
      "      line, which has 'SNP' in column i+1, 'A1' in column i+j+2, 'A2' in column\r\n",
      "      i+j+3, and sample FID/IIDs starting from column i+j+k+4.  (i/j/k are\r\n",
      "      normally zero, but can be changed with 'skip0', 'skip1', and 'skip2'\r\n",
      "      respectively.)  If such a header line is not present,\r\n",
      "      * when all samples appear in the same order as they do in the .fam file,\r\n",
      "        you can use the 'noheader' modifier.\r\n",
      "      * Otherwise, use the 'sepheader' modifier, and append sample ID filenames\r\n",
      "        to your 'list' file entries.\r\n",
      "    * The 'format=' modifier lets you specify the number of values used to\r\n",
      "      represent each dosage.  'format=1' normally indicates a single 0..2 A1\r\n",
      "      expected count; 'dose1' modifies this to a 0..1 frequency.  'format=2'\r\n",
      "      (the default) indicates a 0..1 homozygous A1 likelihood followed by a\r\n",
      "      0..1 het likelihood, while 'format=3' indicates 0..1 hom A1, 0..1 het,\r\n",
      "      0..1 hom A2.\r\n",
      "    * 'Zout' causes the output file to be gzipped.\r\n",
      "    * Normally, an association analysis is performed.  'standard-beta' and\r\n",
      "      'sex' behave as they are supposed to with --linear/--logistic.\r\n",
      "      'case-control-freqs' causes case and control allele frequencies to be\r\n",
      "      reported separately.\r\n",
      "    * There are three alternate modes which cause the association analysis to\r\n",
      "      be skipped.\r\n",
      "      * 'occur' requests a simple variant occurrence report.\r\n",
      "      * --write-dosage causes a simple merged file matching the 'format'\r\n",
      "        specification (not including 'dose1') to be generated.\r\n",
      "      * --score applies a linear scoring system to the dosages.\r\n",
      "\r\n",
      "  --lasso <h2 estimate> [min lambda] ['report-zeroes']\r\n",
      "    Estimate variant effect sizes via LASSO regression.  You must provide an\r\n",
      "    additive heritability estimate to calibrate the regression.\r\n",
      "    Note that this method may require a very large sample size (e.g. hundreds\r\n",
      "    of thousands) to be effective on complex polygenic traits.\r\n",
      "\r\n",
      "  --test-missing ['perm' | 'mperm='<value>] ['perm-count'] ['midp']\r\n",
      "    Check for association between missingness and case/control status, using\r\n",
      "    Fisher's exact test.  (Het. haploids are treated as missing.)\r\n",
      "    The 'midp' modifier causes Lancaster's mid-p adjustment to be applied.\r\n",
      "\r\n",
      "  --make-perm-pheno <ct>\r\n",
      "    Generate phenotype permutations and write them to disk, without invoking an\r\n",
      "    association test.\r\n",
      "\r\n",
      "  --tdt [{exact | exact-midp | poo}] ['perm' | 'mperm='<value>] ['perm-count']\r\n",
      "        [{parentdt1 | parentdt2 | pat | mat}] ['set-test']\r\n",
      "    Report transmission disequilibrium test statistics, given case/control\r\n",
      "    phenotypes and pedigree information.\r\n",
      "    * A Mendel error check is performed before the main tests; offending\r\n",
      "      genotypes are treated as missing by this analysis.\r\n",
      "    * By default, the basic TDT p-value is based on a chi-square test unless\r\n",
      "      you request the exact binomial test with 'exact' or 'exact-midp'.\r\n",
      "    * 'perm'/'mperm=' requests a family-based adaptive or max(T) permutation\r\n",
      "      test.  By default, the permutation test statistic is the basic TDT\r\n",
      "      p-value; 'parentdt1'/'parentdt2' cause parenTDT or combined test\r\n",
      "      p-values, respectively, to be considered instead.\r\n",
      "    * 'set-test' tests the significance of variant sets.  This cannot be used\r\n",
      "      with exact tests for now.\r\n",
      "    The 'poo' modifier causes a parent-of-origin analysis to be performed\r\n",
      "    instead, with transmissions from heterozygous fathers and heterozygous\r\n",
      "    mothers considered separately.\r\n",
      "    * The parent-of-origin analysis does not currently support exact tests.\r\n",
      "    * By default, the permutation test statistic is the absolute\r\n",
      "      parent-of-origin test Z score; 'pat'/'mat' cause paternal or maternal TDT\r\n",
      "      chi-square statistics, respectively, to be considered instead.\r\n",
      "\r\n",
      "  --qfam ['perm' | 'mperm='<value>] ['perm-count'] ['emp-se']\r\n",
      "  --qfam-parents ['perm' | 'mperm='<value>] ['perm-count'] ['emp-se']\r\n",
      "  --qfam-between ['perm' | 'mperm='<value>] ['perm-count'] ['emp-se']\r\n",
      "  --qfam-total ['perm' | 'mperm='<value>] ['perm-count'] ['emp-se']\r\n",
      "    QFAM family-based association test for quantitative traits.\r\n",
      "    * A Mendel error check is performed before the main tests; offending\r\n",
      "      genotypes are treated as missing by this analysis.\r\n",
      "    * This procedure requires permutation.  'perm' and 'perm-count' have the\r\n",
      "      usual meanings.  However, 'mperm='<value> just specifies a fixed number\r\n",
      "      of permutations; the method does not support a proper max(T) test.\r\n",
      "    * The 'emp-se' modifier adds BETA and EMP_SE (empirical standard error for\r\n",
      "      beta) fields to the .perm output file.\r\n",
      "\r\n",
      "  --annotate <PLINK report> ['attrib='<file>] ['ranges='<file>]\r\n",
      "             ['filter='<file>] ['snps='<file>] [{NA | prune}] ['block']\r\n",
      "             ['subset='<file>] ['minimal'] ['distance']\r\n",
      "    Add annotations to a variant-based PLINK report.  This requires an\r\n",
      "    annotation source:\r\n",
      "    * 'attrib='<file> specifies a (possibly gzipped) attribute file.\r\n",
      "    * 'ranges='<file> specifies a gene/range list file.\r\n",
      "    (Both source types can be specified simultaneously.)  The following options\r\n",
      "    are also supported:\r\n",
      "    * 'filter='<file> causes only variants within one of the ranges in the file\r\n",
      "      to be included in the new report.\r\n",
      "    * 'snps='<file> causes only variants named in the file to be included in\r\n",
      "      the new report.\r\n",
      "    * The 'NA' modifier causes unannotated variants to have 'NA' instead of '.'\r\n",
      "      in the new report's ANNOT column, while the 'prune' modifier excludes\r\n",
      "      them entirely.\r\n",
      "    * The 'block' modifier replaces the single ANNOT column with a 0/1-coded\r\n",
      "      column for each possible annotation.\r\n",
      "    * With 'ranges',\r\n",
      "      * 'subset='<file> causes only intervals named in the subset file to be\r\n",
      "        loaded from the ranges file.\r\n",
      "      * interval annotations normally come with a parenthesized signed distance\r\n",
      "        to the interval boundary (0 if the variant is located inside the\r\n",
      "        interval; this is always true without --border).  They can be excluded\r\n",
      "        with the 'minimal' modifier.\r\n",
      "      * the 'distance' modifier adds 'DIST' and 'SGN' columns describing signed\r\n",
      "        distance to the nearest interval.\r\n",
      "    * When --pfilter is present, high p-values are filtered out.\r\n",
      "\r\n",
      "  --clump <PLINK report filename(s)...>\r\n",
      "    Process association analysis report(s) with 'SNP' and p-value columns,\r\n",
      "    organizing results by LD-based clumps.  Multiple filenames can be separated\r\n",
      "    by spaces or commas.\r\n",
      "\r\n",
      "  --gene-report <PLINK report> <gene range file>\r\n",
      "    Generate a gene-based report from a variant-based report.\r\n",
      "    * When --pfilter is present, high p-values are filtered out.\r\n",
      "    * When --extract (without 'range') is present, only variants named in the\r\n",
      "      --extract file are considered.\r\n",
      "\r\n",
      "  --meta-analysis <PLINK report filenames...>\r\n",
      "  --meta-analysis <PLINK report filenames...> + [{logscale | qt}]\r\n",
      "                  [{no-map | no-allele}] ['study'] ['report-all']\r\n",
      "                  ['weighted-z']\r\n",
      "    Perform a meta-analysis on several variant-based reports with 'SNP' and\r\n",
      "    'SE' fields.\r\n",
      "    * Normally, an 'OR' odds ratio field must also be present in each input\r\n",
      "      file.  With 'logscale', 'BETA' log-odds values/regression coefficients\r\n",
      "      are expected instead, but the generated report will still contain odds\r\n",
      "      ratio estimates.  With 'qt', both input and output values are regression\r\n",
      "      betas.\r\n",
      "    * 'CHR', 'BP', and 'A1' fields are also normally required.  'no-map' causes\r\n",
      "      them to all be ignored, while 'no-allele' causes just 'A1' to be ignored.\r\n",
      "    * If 'A2' fields are present, and neither 'no-map' nor 'no-allele' was\r\n",
      "      specified, A1/A2 allele flips are handled properly.  Otherwise, A1\r\n",
      "      mismatches are thrown out.\r\n",
      "    * 'study' causes study-specific effect estimates to be collated in the\r\n",
      "      meta-analysis report.\r\n",
      "    * 'report-all' causes variants present in only a single input file to be\r\n",
      "      included in the meta-analysis report.\r\n",
      "    * 'weighted-z' requests weighted Z-score-based p-values (as computed by the\r\n",
      "      Abecasis Lab's METAL software) in addition to the usual inverse\r\n",
      "      variance-based analysis.  This requires P and effective sample size\r\n",
      "      fields.\r\n",
      "    * When --extract (without 'range') is present, only variants named in the\r\n",
      "      --extract file are considered.\r\n",
      "    * Unless 'no-map' is specified, chromosome filters are also respected.\r\n",
      "\r\n",
      "  --fast-epistasis [{boost | joint-effects | no-ueki}] ['case-only']\r\n",
      "                   [{set-by-set | set-by-all}] ['nop']\r\n",
      "  --epistasis [{set-by-set | set-by-all}]\r\n",
      "    Scan for epistatic interactions.  --fast-epistasis inspects 3x3 joint\r\n",
      "    genotype count tables and only applies to case/control phenotypes, while\r\n",
      "    --epistasis performs linear or logistic regression.\r\n",
      "    * By default, --fast-epistasis uses the PLINK 1.07 allele-based test.  Two\r\n",
      "      newer tests are now supported: 'boost' invokes the likelihood ratio test\r\n",
      "      introduced by Wan X et al. (2010) BOOST: A Fast Approach to Detecting\r\n",
      "      Gene-Gene Interactions in Genome-wide Case-Control Studies, while\r\n",
      "      'joint-effects' applies the joint effects test introduced in Ueki M,\r\n",
      "      Cordell HJ (2012) Improved statistics for genome-wide interaction\r\n",
      "      analysis.\r\n",
      "    * The original --fast-epistasis test normally applies the variance and\r\n",
      "      empty cell corrections suggested by Ueki and Cordell's paper.  To disable\r\n",
      "      them, use the 'no-ueki' modifier.\r\n",
      "    * 'case-only' requests a case-only instead of a case/control test.\r\n",
      "    * By default, all pairs of variants across the entire genome are tested.\r\n",
      "      To just test pairs of variants within a single set, add the 'set-by-set'\r\n",
      "      modifier and load exactly one set with --set/--make-set; with exactly two\r\n",
      "      sets loaded, all variants in one set are tested against all variants in\r\n",
      "      the other.  'set-by-all' tests all variants in one set against the entire\r\n",
      "      genome instead.\r\n",
      "    * 'nop' strips p-values from the main report.\r\n",
      "    * These computations can be subdivided with --parallel; however...\r\n",
      "  --epistasis-summary-merge <common file prefix> <ct>\r\n",
      "    When a --[fast-]epistasis job is subdivided with --parallel, the main\r\n",
      "    report can be assembled at the end by applying Unix 'cat' in the usual\r\n",
      "    manner, but the .summary.1, .summary.2, ... files may require a specialized\r\n",
      "    merge.  --epistasis-summary-merge takes care of the latter.\r\n",
      "\r\n",
      "  --twolocus <variant ID> <variant ID>\r\n",
      "    Two-locus joint genotype count report.\r\n",
      "\r\n",
      "  --score <filename> [i] [j] [k] ['header'] [{sum | no-sum}]\r\n",
      "          [{no-mean-imputation | center}] ['include-cnt'] ['double-dosage']\r\n",
      "    Apply a linear scoring system to each sample.\r\n",
      "    The input file should have one line per scored variant.  Variant IDs are\r\n",
      "    read from column #i, allele codes are read from column #j, and scores are\r\n",
      "    read from column #k, where i defaults to 1, j defaults to i+1, and k\r\n",
      "    defaults to j+1.\r\n",
      "    * The 'header' modifier causes the first nonempty line of the input file to\r\n",
      "      be ignored; otherwise, --score assumes there is no header line.\r\n",
      "    * By default, final scores are averages of the valid per-variant scores.\r\n",
      "      The 'sum' modifier causes sums to be reported instead.  (This cannot be\r\n",
      "      used with 'no-mean-imputation'.  And for backward compatibility, 'sum' is\r\n",
      "      automatically on with dosage data unless 'no-sum' is specified.)\r\n",
      "    * By default, copies of the unnamed allele contribute zero to score, while\r\n",
      "      missing genotypes contribute an amount proportional to the loaded (via\r\n",
      "      --read-freq) or imputed allele frequency.  To throw out missing\r\n",
      "      observations instead (decreasing the denominator in the final average\r\n",
      "      when this happens), use the 'no-mean-imputation' modifier.\r\n",
      "    * Alternatively, you can use the 'center' modifier to shift all scores to\r\n",
      "      mean zero.\r\n",
      "    * This command can be used with dosage data.  By default, the 'CNT' column\r\n",
      "      is omitted from the output file in this case; use 'include-cnt' to keep\r\n",
      "      it.  Also, note that scores are multiplied by 0..1 dosages, not 0..2\r\n",
      "      diploid allele counts, unless the 'double-dosage' modifier is present.\r\n",
      "\r\n",
      "  --R <R script file> ['debug']\r\n",
      "    Connect to a Rserve (preferably version 1.7 or later) background process,\r\n",
      "    and execute the Rplink function defined in the input file.  (Unless the\r\n",
      "    'debug' modifier is present; in that case, the R commands that PLINK would\r\n",
      "    have tried to execute are logged to a file.)\r\n",
      "\r\n",
      "  --write-var-ranges <block ct>\r\n",
      "    Divide the set of variants into equal-size blocks.  (Can be used with\r\n",
      "    --snps to split a job across multiple machines.)\r\n",
      "\r\n",
      "The following other flags are supported.  (Order of operations is described at\r\n",
      "https://www.cog-genomics.org/plink/1.9/order .)\r\n",
      "  --script <fname> : Include command-line options from file.\r\n",
      "  --rerun [log]    : Rerun commands in log (default 'plink.log').\r\n",
      "  --version        : Display only version number before exiting.\r\n",
      "  --silent         : Suppress output to console.\r\n",
      "  --gplink         : Reserved for interoperation with gPLINK.\r\n",
      "  --missing-genotype <char> : Set missing genotype code (normally '0').\r\n",
      "  --double-id          : Set both FIDs and IIDs to the VCF/BCF sample ID.\r\n",
      "  --const-fid [ID]     : Set all FIDs to the given constant (default '0').\r\n",
      "  --id-delim [d]       : Parse sample IDs as <FID><d><IID> (default delim '_').\r\n",
      "  --vcf-idspace-to <c> : Convert spaces in sample IDs to the given character.\r\n",
      "  --biallelic-only ['strict'] ['list'] : Skip VCF variants with 2+ ALT alleles.\r\n",
      "  --vcf-min-qual <val>           : Skip VCF variants with low/missing QUAL.\r\n",
      "  --vcf-filter [exception(s)...] : Skip variants which have FILTER failures.\r\n",
      "  --vcf-require-gt               : Skip variants with no GT field.\r\n",
      "  --vcf-min-gq <val>             : No-call a genotype when GQ is below the\r\n",
      "                                   given threshold.\r\n",
      "  --vcf-min-gp <val>             : No-call a genotype when 0-1 scaled GP is\r\n",
      "                                   below the given threshold.\r\n",
      "  --vcf-half-call <m>  : Specify how '0/.' and similar VCF GT values should be\r\n",
      "                         handled.  The following four modes are supported:\r\n",
      "                         * 'error'/'e' (default) errors out and reports line #.\r\n",
      "                         * 'haploid'/'h' treats them as haploid calls.\r\n",
      "                         * 'missing'/'m' treats them as missing.\r\n",
      "                         * 'reference'/'r' treats the missing value as 0.\r\n",
      "  --oxford-single-chr <chr nm> : Specify single-chromosome .gen file with\r\n",
      "                                 ignorable first column.\r\n",
      "  --oxford-pheno-name <col nm> : Import named phenotype from the .sample file.\r\n",
      "  --hard-call-threshold <val>  : When an Oxford-format fileset is loaded, calls\r\n",
      "  --hard-call-threshold random   with uncertainty level greater than 0.1 are\r\n",
      "                                 normally treated as missing.  You can adjust\r\n",
      "                                 this threshold by providing a numeric\r\n",
      "                                 parameter, or randomize all calls with\r\n",
      "                                 'random'.\r\n",
      "  --missing-code [string list] : Comma-delimited list of missing phenotype\r\n",
      "    (alias: --missing_code)      values for Oxford-format filesets (def. 'NA').\r\n",
      "  --simulate-ncases <num>   : Set --simulate case count (default 1000).\r\n",
      "  --simulate-ncontrols <n>  : Set --simulate control count (default 1000).\r\n",
      "  --simulate-prevalence <p> : Set --simulate disease prevalence (default 0.01).\r\n",
      "  --simulate-n <num>        : Set --simulate-qt sample count (default 1000).\r\n",
      "  --simulate-label <prefix> : Set --simulate[-qt] FID/IID name prefix.\r\n",
      "  --simulate-missing <freq> : Set --simulate[-qt] missing genotype frequency.\r\n",
      "  --allow-extra-chr ['0']   : Permit unrecognized chromosome codes.  The '0'\r\n",
      "    (alias: --aec)            modifier causes them to be treated as if they had\r\n",
      "                              been set to zero.\r\n",
      "  --chr-set <autosome ct> ['no-x'] ['no-y'] ['no-xy'] ['no-mt'] :\r\n",
      "    Specify a nonhuman chromosome set.  The first parameter sets the number of\r\n",
      "    diploid autosome pairs if positive, or haploid chromosomes if negative.\r\n",
      "    Given diploid autosomes, the remaining modifiers indicate the absence of\r\n",
      "    the named non-autosomal chromosomes.\r\n",
      "  --cow/--dog/--horse/--mouse/--rice/--sheep : Shortcuts for those species.\r\n",
      "  --autosome-num <value>    : Alias for \"--chr-set <value> no-y no-xy no-mt\".\r\n",
      "  --cm-map <fname pattern> [chr] : Use SHAPEIT-format recombination maps to set\r\n",
      "                                   centimorgan positions.  To process more than\r\n",
      "                                   one chromosome, include a '@' in the first\r\n",
      "                                   parameter where the chrom. number belongs,\r\n",
      "                                   e.g. 'genetic_map_chr@_combined_b37.txt'.\r\n",
      "  --zero-cms         : Zero out centimorgan positions.\r\n",
      "  --allow-no-samples : Allow the input fileset to contain no samples.\r\n",
      "  --allow-no-vars    : Allow the input fileset to contain no variants.\r\n",
      "  --pheno <fname>  : Load phenotype data from the specified file, instead of\r\n",
      "                     using the values in the main input fileset.\r\n",
      "  --all-pheno      : For basic association tests, loop through all phenotypes\r\n",
      "                     in --pheno file.\r\n",
      "  --mpheno <n>     : Load phenotype from column (n+2) in --pheno file.\r\n",
      "  --pheno-name <c> : If --pheno file has a header row, use column with the\r\n",
      "                     given name.\r\n",
      "  --pheno-merge    : When the main input fileset contains an phenotype value\r\n",
      "                     for a sample, but the --pheno file does not, use the\r\n",
      "                     original value instead of treating the phenotype as\r\n",
      "                     missing.\r\n",
      "  --missing-phenotype <v> : Set missing phenotype value (normally -9).\r\n",
      "  --1                     : Expect case/control phenotypes to be coded as\r\n",
      "                            0 = control, 1 = case, instead of the usual\r\n",
      "                            0 = missing, 1 = control, 2 = case.  This also\r\n",
      "                            forces phenotypes to be interpreted as case/ctrl.\r\n",
      "  --make-pheno <fn> <val> : Define a new case/control phenotype.  If the val\r\n",
      "                            parameter is '*', all samples listed in the given\r\n",
      "                            file are cases, and everyone else is a control.\r\n",
      "                            (Note that, in some shells, it is necessary to\r\n",
      "                            surround the * with quotes.)\r\n",
      "                            Otherwise, all samples with third column entry\r\n",
      "                            equal to the val parameter are cases, and all other\r\n",
      "                            samples mentioned in the file are controls.\r\n",
      "  --tail-pheno <Lt> [Hbt] : Downcode a scalar phenotype to a case/control\r\n",
      "                            phenotype.  All samples with phenotype values\r\n",
      "                            greater than Hbt are cases, and all with values\r\n",
      "                            less than or equal to Lt are controls.  If Hbt is\r\n",
      "                            unspecified, it is equal to Lt; otherwise,\r\n",
      "                            in-between phenotype values are set to missing.\r\n",
      "  --covar <filename> ['keep-pheno-on-missing-cov'] : Specify covariate file.\r\n",
      "  --covar-name <...>       : Specify covariate(s) in --covar file by name.\r\n",
      "                             Separate multiple names with spaces or commas, and\r\n",
      "                             use dashes to designate ranges.\r\n",
      "  --covar-number <...>     : Specify covariate(s) in --covar file by index.\r\n",
      "  --no-const-covar         : Exclude constant covariates.\r\n",
      "  --allow-no-covars        : Allow no covariates to be loaded from --covar\r\n",
      "                             file.\r\n",
      "  --within <f> ['keep-NA'] : Specify initial cluster assignments.\r\n",
      "  --mwithin <n>            : Load cluster assignments from column n+2.\r\n",
      "  --family                 : Create a cluster for each family ID.\r\n",
      "  --loop-assoc <f> ['keep-NA']  : Run specified case/control association\r\n",
      "                                  commands once for each cluster in the file,\r\n",
      "                                  using cluster membership as the phenotype.\r\n",
      "  --set <filename>              : Load sets from a .set file.\r\n",
      "  --set-names <name(s)...>      : Load only sets named on the command line.\r\n",
      "                                  Use spaces to separate multiple names.\r\n",
      "  --subset <filename>           : Load only sets named in the given text file.\r\n",
      "  --set-collapse-all <set name> : Merge all sets.\r\n",
      "  --complement-sets             : Invert all sets.  (Names gain 'C_' prefixes.)\r\n",
      "  --make-set-complement-all <s> : --set-collapse-all + inversion.\r\n",
      "  --make-set <filename>         : Define sets from a list of named bp ranges.\r\n",
      "  --make-set-border <kbs>       : Stretch regions in --make-set file.\r\n",
      "  --make-set-collapse-group     : Define sets from groups instead of sets in\r\n",
      "                                  --make-set file.\r\n",
      "  --keep <filename>       : Exclude all samples not named in the file.\r\n",
      "  --remove <filename>     : Exclude all samples named in the file.\r\n",
      "  --keep-fam <filename>   : Exclude all families not named in the file.\r\n",
      "  --remove-fam <filename> : Exclude all families named in the file.\r\n",
      "  --extract ['range'] <f> : Exclude all variants not named in the file.\r\n",
      "  --exclude ['range'] <f> : Exclude all variants named in the file.\r\n",
      "  --keep-clusters <filename>          : These can be used individually or in\r\n",
      "  --keep-cluster-names <name(s)...>     combination to define a list of\r\n",
      "                                        clusters to keep; all samples not in a\r\n",
      "                                        cluster in that list are then excluded.\r\n",
      "                                        Use spaces to separate cluster names\r\n",
      "                                        for --keep-cluster-names.\r\n",
      "  --remove-clusters <filename>        : Exclude all clusters named in the file.\r\n",
      "  --remove-cluster-names <name(s)...> : Exclude the named clusters.\r\n",
      "  --gene <sets...> : Exclude variants not in a set named on the command line.\r\n",
      "                     (Separate multiple set names with spaces.)\r\n",
      "  --gene-all       : Exclude variants which aren't a member of any set.  (PLINK\r\n",
      "                     1.07 automatically did this under some circumstances.)\r\n",
      "  --attrib <f> [att lst] : Given a file assigning attributes to variants, and a\r\n",
      "  --attrib-indiv <f> [a]   comma-delimited list (with no whitespace) of\r\n",
      "                           attribute names, remove variants/samples which are\r\n",
      "                           either missing from the file or don't have any of\r\n",
      "                           the listed attributes.  If some attribute names in\r\n",
      "                           the list are preceded by '-', they are treated as\r\n",
      "                           \"negative match conditions\" instead: variants with\r\n",
      "                           at least one negative match attribute are removed.\r\n",
      "                           The first character in the list cannot be a '-', due\r\n",
      "                           to how command-line parsing works; add a comma in\r\n",
      "                           front to get around this.\r\n",
      "  --chr <chrs...>  : Exclude all variants not on the given chromosome(s).\r\n",
      "                     Valid choices for humans are 0 (unplaced), 1-22, X, Y, XY,\r\n",
      "                     and MT.  Separate multiple chromosomes with spaces and/or\r\n",
      "                     commas, and use a dash (no adjacent spaces permitted) to\r\n",
      "                     denote a range, e.g. \"--chr 1-4, 22, xy\".\r\n",
      "  --not-chr <...>  : Reverse of --chr (exclude variants on listed chromosomes).\r\n",
      "  --autosome       : Exclude all non-autosomal variants.\r\n",
      "  --autosome-xy    : Exclude all non-autosomal variants, except those with\r\n",
      "                     chromosome code XY (pseudo-autosomal region of X).\r\n",
      "  --snps-only ['just-acgt'] : Exclude non-SNP variants.  By default, SNP = both\r\n",
      "                              allele codes are single-character; 'just-acgt'\r\n",
      "                              restricts codes to {A,C,G,T,a,c,g,t,<missing>}.\r\n",
      "  --from <var ID>  : Use ID(s) to specify a variant range to load.  When used\r\n",
      "  --to   <var ID>    together, both variants must be on the same chromosome.\r\n",
      "  --snp  <var ID>  : Specify a single variant to load.\r\n",
      "  --exclude-snp <> : Specify a single variant to exclude.\r\n",
      "  --window  <kbs>  : With --snp or --exclude-snp, loads/excludes all variants\r\n",
      "                     within half the specified kb distance of the named one.\r\n",
      "  --from-bp <pos>  : Use physical position(s) to define a variant range to\r\n",
      "  --to-bp   <pos>    load.  --from-kb/--to-kb/--from-mb/--to-mb allow decimal\r\n",
      "  --from-kb <pos>    values.  You must also specify a single chromosome (using\r\n",
      "  --to-kb   <pos>    e.g. --chr) when using these flags.\r\n",
      "  --from-mb <pos>\r\n",
      "  --to-mb   <pos>\r\n",
      "  --snps <var IDs...>  : Use IDs to specify variant range(s) to load or\r\n",
      "  --exclude-snps <...>   exclude.  E.g. \"--snps rs1111-rs2222, rs3333, rs4444\".\r\n",
      "  --thin <p>       : Randomly remove variants, retaining each with prob. p.\r\n",
      "  --thin-count <n> : Randomly remove variants until n of them remain.\r\n",
      "  --bp-space <bps> : Remove variants so that each pair is no closer than the\r\n",
      "                     given bp distance.  (Equivalent to VCFtools --thin.)\r\n",
      "  --thin-indiv <p>         : Randomly remove samples, retaining with prob. p.\r\n",
      "  --thin-indiv-count <n>   : Randomly remove samples until n of them remain.\r\n",
      "  --filter <f> <val(s)...> : Exclude all samples without a 3rd column entry in\r\n",
      "                             the given file matching one of the given\r\n",
      "                             space-separated value(s).\r\n",
      "  --mfilter <n>            : Match against (n+2)th column instead.\r\n",
      "  --geno [val]     : Exclude variants with missing call frequencies greater\r\n",
      "                     than a threshold (default 0.1).  (Note that the default\r\n",
      "                     threshold is only applied if --geno is invoked without a\r\n",
      "                     parameter; when --geno is not invoked, no per-variant\r\n",
      "                     missing call frequency ceiling is enforced at all.  Other\r\n",
      "                     inclusion/exclusion default thresholds work the same way.)\r\n",
      "  --mind [val]     : Exclude samples with missing call frequencies greater than\r\n",
      "                     a threshold (default 0.1).\r\n",
      "  --oblig-missing <f1> <f2> : Specify blocks of missing genotype calls for\r\n",
      "                              --geno/--mind to ignore.  The first file should\r\n",
      "                              have variant IDs in the first column and block\r\n",
      "                              IDs in the second, while the second file should\r\n",
      "                              have FIDs in the first column, IIDs in the\r\n",
      "                              second, and block IDs in the third.\r\n",
      "  --prune             : Remove samples with missing phenotypes.\r\n",
      "  --maf [freq]        : Exclude variants with minor allele frequency lower than\r\n",
      "                        a threshold (default 0.01).\r\n",
      "  --max-maf <freq>    : Exclude variants with MAF greater than the threshold.\r\n",
      "  --mac <ct>          : Exclude variants with minor allele count lower than the\r\n",
      "    (alias: --min-ac)   given threshold.\r\n",
      "  --max-mac <ct>      : Exclude variants with minor allele count greater than\r\n",
      "    (alias: --max-ac)   the given threshold.\r\n",
      "  --maf-succ       : Rule of succession MAF estimation (used in EIGENSOFT).\r\n",
      "                     Given j observations of one allele and k >= j observations\r\n",
      "                     of the other, infer a MAF of (j+1) / (j+k+2), rather than\r\n",
      "                     the default j / (j+k).\r\n",
      "  --read-freq <fn> : Estimate MAFs and heterozygote frequencies from the given\r\n",
      "                     --freq[x] report, instead of the input fileset.\r\n",
      "  --hwe <p> ['midp'] ['include-nonctrl'] : Exclude variants with Hardy-Weinberg\r\n",
      "                                           equilibrium exact test p-values\r\n",
      "                                           below a threshold.\r\n",
      "  --me <t> <v> ['var-first'] : Filter out trios and variants with Mendel error\r\n",
      "                               rates exceeding the given thresholds.\r\n",
      "  --me-exclude-one [ratio]   : Make --me exclude only one sample per trio.\r\n",
      "  --qual-scores <f> [qcol] [IDcol] [skip] : Filter out variants with\r\n",
      "                                            out-of-range quality scores.\r\n",
      "                                            Default range is now [0, \\infty ).\r\n",
      "  --qual-threshold <min qual score>       : Set --qual-scores range floor.\r\n",
      "  --qual-max-threshold <max qual score>   : Set --qual-scores range ceiling.\r\n",
      "  --allow-no-sex   : Do not treat ambiguous-sex samples as having missing\r\n",
      "                     phenotypes in analysis commands.  (Automatic /w --no-sex.)\r\n",
      "  --must-have-sex  : Force ambiguous-sex phenotypes to missing on\r\n",
      "                     --make-bed/--make-just-fam/--recode/--write-covar.\r\n",
      "  --filter-cases       : Include only cases in the current analysis.\r\n",
      "  --filter-controls    : Include only controls.\r\n",
      "  --filter-males       : Include only males.\r\n",
      "  --filter-females     : Include only females.\r\n",
      "  --filter-founders    : Include only founders.\r\n",
      "  --filter-nonfounders : Include only nonfounders.\r\n",
      "  --nonfounders        : Include nonfounders in allele freq/HWE calculations.\r\n",
      "  --make-founders ['require-2-missing'] ['first'] :\r\n",
      "    Clear parental IDs for those with 1+ missing parent(s).\r\n",
      "  --recode-allele <fn> : With --recode A/A-transpose/AD, count alleles named in\r\n",
      "                         the file (otherwise A1 alleles are always counted).\r\n",
      "  --output-chr <MT code> : Set chromosome coding scheme in output files by\r\n",
      "                           providing the desired human mitochondrial code.\r\n",
      "                           (Options are '26', 'M', 'MT', '0M', 'chr26', 'chrM',\r\n",
      "                           and 'chrMT'.)\r\n",
      "  --output-missing-genotype <ch> : Set the code used to represent missing\r\n",
      "                                   genotypes in output files (normally the\r\n",
      "                                   --missing-genotype value).\r\n",
      "  --output-missing-phenotype <s> : Set the string used to represent missing\r\n",
      "                                   phenotypes in output files (normally the\r\n",
      "                                   --missing-phenotype value).\r\n",
      "  --zero-cluster <f> : In combination with --within/--family, set blocks of\r\n",
      "                       genotype calls to missing.  The input file should have\r\n",
      "                       variant IDs in the first column and cluster IDs in the\r\n",
      "                       second.  This must now be used with --make-bed and no\r\n",
      "                       other output commands.\r\n",
      "  --set-hh-missing       : Cause --make-bed and --recode to set heterozygous\r\n",
      "                           haploid genotypes to missing.\r\n",
      "  --set-mixed-mt-missing : Cause --make-bed and --recode to set mixed MT\r\n",
      "                           genotypes to missing.\r\n",
      "  --split-x <bp1> <bp2> ['no-fail']\r\n",
      "  --split-x <build> ['no-fail'] :\r\n",
      "    Changes chromosome code of all chrX variants with bp position <= bp1 or >=\r\n",
      "    bp2 to XY.  The following build codes are supported as shorthand:\r\n",
      "    * 'b36'/'hg18' = NCBI 36, 2709521/154584237\r\n",
      "    * 'b37'/'hg19' = GRCh37, 2699520/154931044\r\n",
      "    * 'b38'/'hg38' = GRCh38, 2781479/155701383\r\n",
      "    By default, PLINK errors out when no variants would be affected by\r\n",
      "    --split-x; the 'no-fail' modifier (useful in scripts) overrides this.\r\n",
      "  --merge-x ['no-fail'] : Merge XY chromosome back with X.\r\n",
      "  --set-me-missing      : Cause --make-bed to set Mendel errors to missing.\r\n",
      "  --fill-missing-a2     : Cause --make-bed to replace all missing calls with\r\n",
      "                          homozygous A2 calls.\r\n",
      "  --set-missing-var-ids <t>   : Given a template string with a '@' where the\r\n",
      "                                chromosome code should go and '#' where the bp\r\n",
      "                                coordinate belongs, --set-missing-var-ids\r\n",
      "                                assigns chromosome-and-bp-based IDs to unnamed\r\n",
      "                                variants.\r\n",
      "                                You may also use '$1' and '$2' to refer to\r\n",
      "                                allele names in the template string, and in\r\n",
      "                                fact this becomes essential when multiple\r\n",
      "                                variants share the same coordinate.\r\n",
      "  --new-id-max-allele-len <n> : Specify maximum number of leading characters\r\n",
      "                                from allele names to include in new variant IDs\r\n",
      "                                (default 23).\r\n",
      "  --missing-var-code <string> : Change unnamed variant code (default '.').\r\n",
      "  --update-chr  <f> [chrcol] [IDcol]  [skip] : Update variant chromosome codes.\r\n",
      "  --update-cm   <f> [cmcol]  [IDcol]  [skip] : Update centimorgan positions.\r\n",
      "  --update-map  <f> [bpcol]  [IDcol]  [skip] : Update variant bp positions.\r\n",
      "  --update-name <f> [newcol] [oldcol] [skip] : Update variant IDs.\r\n",
      "  --update-alleles <fname> : Update variant allele codes.\r\n",
      "  --allele1234 ['multichar'] : Interpret/recode A/C/G/T alleles as 1/2/3/4.\r\n",
      "                               With 'multichar', converts all A/C/G/Ts in\r\n",
      "                               allele names to 1/2/3/4s.\r\n",
      "  --alleleACGT ['multichar'] : Reverse of --allele1234.\r\n",
      "  --update-ids <f>     : Update sample IDs.\r\n",
      "  --update-parents <f> : Update parental IDs.\r\n",
      "  --update-sex <f> [n] : Update sexes.  Sex (1 or M = male, 2 or F = female, 0\r\n",
      "                         = missing) is loaded from column n+2 (default n is 1).\r\n",
      "  --flip <filename>    : Flip alleles (A<->T, C<->G) for SNP IDs in the file.\r\n",
      "  --flip-subset <fn>   : Only apply --flip to samples in --flip-subset file.\r\n",
      "  --flip-scan-window <ct+1> : Set --flip-scan max variant ct dist. (def. 10).\r\n",
      "  --flip-scan-window-kb <x> : Set --flip-scan max kb distance (default 1000).\r\n",
      "  --flip-scan-threshold <x> : Set --flip-scan min correlation (default 0.5).\r\n",
      "  --keep-allele-order  : Keep the allele order defined in the .bim file,\r\n",
      "  --real-ref-alleles     instead of forcing A2 to be the major allele.\r\n",
      "                         --real-ref-alleles also removes 'PR' from the INFO\r\n",
      "                         values emitted by --recode vcf{,-fid,-iid}.\r\n",
      "  --a1-allele <f> [a1col] [IDcol] [skip] : Force alleles in the file to A1.\r\n",
      "  --a2-allele <filename> [a2col] [IDcol] [skip] :\r\n",
      "    Force alleles in the file to A2.  (\"--a2-allele <VCF filename> 4 3 '#'\",\r\n",
      "    which scrapes reference allele assignments from a VCF file, is especially\r\n",
      "    useful.)\r\n",
      "  --indiv-sort <m> [f] : Specify FID/IID sort order.  The following four modes\r\n",
      "                         are supported:\r\n",
      "                         * 'none'/'0' keeps samples in the order they were\r\n",
      "                           loaded.  Default for non-merge operations.\r\n",
      "                         * 'natural'/'n' invokes 'natural sort', e.g.\r\n",
      "                           'id2' < 'ID3' < 'id10'.  Default when merging.\r\n",
      "                         * 'ascii'/'a' sorts in ASCII order, e.g.\r\n",
      "                           'ID3' < 'id10' < 'id2'.\r\n",
      "                         * 'file'/'f' uses the order in the given file (named\r\n",
      "                           in the second parameter).\r\n",
      "                         For now, only --merge/--bmerge/--merge-list and\r\n",
      "                         --make-bed/--make-just-fam respect this flag.\r\n",
      "  --with-phenotype ['no-parents'] [{no-sex | female-2}] :\r\n",
      "    Include more sample info in new .cov file.\r\n",
      "  --dummy-coding [N] ['no-round'] : Split categorical variables (n categories,\r\n",
      "                                    2 < n <= N, default N is 49) into n-1\r\n",
      "                                    binary dummy variables when writing\r\n",
      "                                    covariate file.\r\n",
      "  --merge-mode <n>   : Adjust --[b]merge/--merge-list behavior based on a\r\n",
      "                       numeric code.\r\n",
      "                       1 (default) = ignore missing calls, otherwise difference\r\n",
      "                                     -> missing\r\n",
      "                       2 = only overwrite originally missing calls\r\n",
      "                       3 = only overwrite when nonmissing in new file\r\n",
      "                       4/5 = never overwrite and always overwrite, respectively\r\n",
      "                       6 = report all mismatching calls without merging\r\n",
      "                       7 = report mismatching nonmissing calls without merging\r\n",
      "  --merge-equal-pos  : With --merge/--bmerge/--merge-list, merge variants with\r\n",
      "                       different names but identical positions.  (Exception:\r\n",
      "                       same-position chromosome code 0 variants aren't merged.)\r\n",
      "  --mendel-duos      : Make Mendel error checks consider samples with only one\r\n",
      "                       parent in the dataset.\r\n",
      "  --mendel-multigen  : Make Mendel error checks consider (great-)grandparental\r\n",
      "                       genotypes when parental genotype data is missing.\r\n",
      "  --ld-window <ct+1> : Set --r/--r2 max variant ct pairwise distance (usu. 10).\r\n",
      "  --ld-window-kb <x> : Set --r/--r2 max kb pairwise distance (usually 1000).\r\n",
      "  --ld-window-cm <x> : Set --r/--r2 max centimorgan pairwise distance.\r\n",
      "  --ld-window-r2 <x> : Set threshold for --r2 report inclusion (usually 0.2).\r\n",
      "  --ld-snp <var ID>  : Set first variant in all --r/--r2 pairs.\r\n",
      "  --ld-snps <vID...> : Restrict first --r/--r2 variant to the given ranges.\r\n",
      "  --ld-snp-list <f>  : Restrict first --r/--r2 var. to those named in the file.\r\n",
      "  --list-all         : Generate the 'all' mode report when using --show-tags in\r\n",
      "                       file mode.\r\n",
      "  --tag-kb <kbs>     : Set --show-tags max tag kb distance (default 250).\r\n",
      "  --tag-r2 <val>     : Set --show-tags min tag r-squared (default 0.8)\r\n",
      "  --tag-mode2        : Use two-column --show-tags (file mode) I/O format.\r\n",
      "  --ld-xchr <code>   : Set chrX model for --indep[-pairwise], --r/--r2,\r\n",
      "                       --flip-scan, and --show-tags.\r\n",
      "                       1 (default) = males coded 0/1, females 0/1/2 (A1 dosage)\r\n",
      "                       2 = males coded 0/2\r\n",
      "                       3 = males coded 0/2, but females given double weighting\r\n",
      "  --blocks-max-kb <kbs>      : Set --blocks maximum haploblock span (def. 200).\r\n",
      "  --blocks-min-maf <cutoff>  : Adjust --blocks MAF minimum (default 0.05).\r\n",
      "  --blocks-strong-lowci <x>  : Set --blocks \"strong LD\" CI thresholds (defaults\r\n",
      "  --blocks-strong-highci <x>   0.70 and 0.98).\r\n",
      "  --blocks-recomb-highci <x> : Set 'recombination' CI threshold (default 0.90).\r\n",
      "  --blocks-inform-frac <x>   : Force haploblock <strong LD pairs>:<total\r\n",
      "                               informative pairs> ratios to be larger than this\r\n",
      "                               value (default 0.95).\r\n",
      "  --distance-wts exp=<x>        : When computing genomic distances, assign each\r\n",
      "                                  variant a weight of (2q(1-q))^{-x}, where q\r\n",
      "                                  is the loaded or inferred MAF.\r\n",
      "  --read-dists <dist file> [id file] : Load a triangular binary distance matrix\r\n",
      "                                       instead of recalculating from scratch.\r\n",
      "  --ppc-gap <val>    : Minimum number of base pairs, in thousands, between\r\n",
      "                       informative pairs of markers used in --genome PPC test.\r\n",
      "                       500 if unspecified.\r\n",
      "  --min <cutoff>     : Specify minimum PI_HAT for inclusion in --genome report.\r\n",
      "  --max <cutoff>     : Specify maximum PI_HAT for inclusion in --genome report.\r\n",
      "  --homozyg-match <> : Set minimum concordance across jointly homozygous\r\n",
      "                       variants for a pairwise allelic match to be declared.\r\n",
      "  --pool-size <ct>   : Set minimum size of pools in \"--homozyg group\" report.\r\n",
      "  --read-genome <fn> : Load --genome report for --cluster/--neighbour, instead\r\n",
      "                       of recalculating IBS and PPC test p-values from scratch.\r\n",
      "  --ppc <p-val>    : Specify minimum PPC test p-value within a cluster.\r\n",
      "  --mc <max size>  : Specify maximum cluster size.\r\n",
      "  --mcc <c1> <c2>  : Specify maximum case and control counts per cluster.\r\n",
      "  --K <min count>  : Specify minimum cluster count.\r\n",
      "  --ibm <val>      : Specify minimum identity-by-missingness.\r\n",
      "  --match <f> [mv] : Use covariate values to restrict clustering.  Without\r\n",
      "                     --match-type, two samples can only be in the same cluster\r\n",
      "                     if all covariates match.  The optional second parameter\r\n",
      "                     specifies a covariate value to treat as missing.\r\n",
      "  --match-type <f> : Refine interpretation of --match file.  The --match-type\r\n",
      "                     file is expected to be a single line with as many entries\r\n",
      "                     as the --match file has covariates; '0' entries specify\r\n",
      "                     \"negative matches\" (i.e. samples with equal covariate\r\n",
      "                     values cannot be in the same cluster), '1' entries specify\r\n",
      "                     \"positive matches\" (default), and '-1' causes the\r\n",
      "                     corresponding covariate to be ignored.\r\n",
      "  --qmatch <f> [m] : Force all members of a cluster to have similar\r\n",
      "  --qt <fname>       quantitative covariate values.  The --qmatch file contains\r\n",
      "                     the covariate values, while the --qt file is a list of\r\n",
      "                     nonnegative tolerances (and '-1's marking covariates to\r\n",
      "                     skip).\r\n",
      "  --pca-cluster-names <...> : These can be used individually or in combination\r\n",
      "  --pca-clusters <fname>      to define a list of clusters to use in the basic\r\n",
      "                              --pca computation.  (--pca-cluster-names expects\r\n",
      "                              a space-delimited sequence of cluster names,\r\n",
      "                              while --pca-clusters expects a file with one\r\n",
      "                              cluster name per line.)  All samples outside\r\n",
      "                              those clusters will then be projected on to the\r\n",
      "                              calculated PCs.\r\n",
      "  --mds-plot <dims> ['by-cluster'] ['eigendecomp'] ['eigvals'] :\r\n",
      "    Multidimensional scaling analysis.  Requires --cluster.\r\n",
      "  --cell <thresh>  : Skip some --model tests when a contingency table entry is\r\n",
      "                     smaller than the given threshold.\r\n",
      "  --condition <var ID> [{dominant | recessive}] : Add one variant as a --linear\r\n",
      "                                                  or --logistic covariate.\r\n",
      "  --condition-list <f> [{dominant | recessive}] : Add variants named in the\r\n",
      "                                                  file as --linear/--logistic\r\n",
      "                                                  covariates.\r\n",
      "  --parameters <...>  : Include only the given covariates/interactions in the\r\n",
      "                        --linear/--logistic models, identified by a list of\r\n",
      "                        1-based indices and/or ranges of them.\r\n",
      "  --tests <all> [...] : Perform a (joint) test on the specified term(s) in the\r\n",
      "                        --linear/--logistic model, identified by 1-based\r\n",
      "                        indices and/or ranges of them.  If permutation was\r\n",
      "                        requested, it is based on this test.\r\n",
      "                        * Note that, when --parameters is also present, the\r\n",
      "                          indices refer to the terms remaining AFTER pruning by\r\n",
      "                          --parameters.\r\n",
      "                        * You can use \"--tests all\" to include all terms.\r\n",
      "  --vif <max VIF>     : Set VIF threshold for --linear multicollinearity check\r\n",
      "                        (default 50).\r\n",
      "  --xchr-model <code> : Set the X chromosome --linear/--logistic model.\r\n",
      "                        0 = skip sex and haploid chromosomes\r\n",
      "                        1 (default) = add sex as a covariate on X chromosome\r\n",
      "                        2 = code male genotypes 0/2 instead of 0/1\r\n",
      "                        3 = test for interaction between genotype and sex\r\n",
      "  --lasso-select-covars [cov(s)...] : Subject some or all covariates to LASSO\r\n",
      "                                      model selection.\r\n",
      "  --adjust ['gc'] ['log10'] ['qq-plot'] : Report some multiple-testing\r\n",
      "                                          corrections.\r\n",
      "  --lambda <val>   : Set genomic control lambda for --adjust.\r\n",
      "  --ci <size>      : Report confidence intervals for odds ratios.\r\n",
      "  --pfilter <val>  : Filter out association test results with higher p-values.\r\n",
      "  --aperm <min perms - 1> [max perms] [alpha] [beta] [init interval] [slope] :\r\n",
      "    Set up to six parameters controlling adaptive permutation tests.\r\n",
      "    * The first two control the minimum and maximum number of permutations that\r\n",
      "      may be run for each variant; default values are 5 and 1000000.\r\n",
      "    * The next two control the early termination condition.  A\r\n",
      "      100% * (1 - beta/2T) confidence interval is calculated for each empirical\r\n",
      "      p-value, where T is the total number of variants; whenever this\r\n",
      "      confidence interval doesn't contain alpha, the variant is exempted from\r\n",
      "      further permutation testing.  Default values are 0 and 1e-4.\r\n",
      "    * The last two control when the early termination condition is checked.  If\r\n",
      "      a check occurs at permutation #p, the next check occurs after\r\n",
      "      <slope>p + <init interval> more permutations (rounded down).  Default\r\n",
      "      initial interval is 1, and default slope is 0.001.\r\n",
      "  --mperm-save     : Save best max(T) permutation test statistics.\r\n",
      "  --mperm-save-all : Save all max(T) permutation test statistics.\r\n",
      "  --set-p <p-val>        : Adjust set test significant variant p-value ceiling\r\n",
      "                           (default 0.05).\r\n",
      "  --set-r2 [v] ['write'] : Adjust set test significant variant pairwise r^2\r\n",
      "                           ceiling (default 0.5).  'write' causes violating\r\n",
      "                          pairs to be dumped to <output prefix>.ldset.\r\n",
      "  --set-max <ct>         : Adjust set test maximum # of significant variants\r\n",
      "                           considered per set (default 5).\r\n",
      "  --set-test-lambda <v>  : Specify genomic control correction for set test.\r\n",
      "  --border <kbs>            : Extend --annotate range intervals by given # kbs.\r\n",
      "  --annotate-snp-field <nm> : Set --annotate variant ID field name.\r\n",
      "  --clump-p1 <pval> : Set --clump index var. p-value ceiling (default 1e-4).\r\n",
      "  --clump-p2 <pval> : Set --clump secondary p-value threshold (default 0.01).\r\n",
      "  --clump-r2 <r^2>  : Set --clump r^2 threshold (default 0.5).\r\n",
      "  --clump-kb <kbs>  : Set --clump kb radius (default 250).\r\n",
      "  --clump-snp-field <n...>  : Set --clump variant ID field name (default\r\n",
      "                              'SNP').  With multiple field names, earlier names\r\n",
      "                              take precedence over later ones.\r\n",
      "  --clump-field <name...>   : Set --clump p-value field name (default 'P').\r\n",
      "  --clump-allow-overlap     : Let --clump non-index vars. join multiple clumps.\r\n",
      "  --clump-verbose           : Request extended --clump report.\r\n",
      "  --clump-annotate <hdr...> : Include named extra fields in --clump-verbose and\r\n",
      "                              --clump-best reports.  (Field names can be\r\n",
      "                              separated with spaces or commas.)\r\n",
      "  --clump-range <filename>  : Report overlaps between clumps and regions.\r\n",
      "  --clump-range-border <kb> : Stretch regions in --clump-range file.\r\n",
      "  --clump-index-first       : Extract --clump index vars. from only first file.\r\n",
      "  --clump-replicate         : Exclude clumps which contain secondary results\r\n",
      "                              from only one file.\r\n",
      "  --clump-best              : Report best proxy for each --clump index var.\r\n",
      "  --meta-analysis-chr-field <n...> : Set --meta-analysis chromosome, variant\r\n",
      "  --meta-analysis-snp-field <n...>   ID, position, A1/A2 allele, p-value,\r\n",
      "  --meta-analysis-bp-field <n...>    standard error, and/or effective sample\r\n",
      "  --meta-analysis-a1-field <n...>    size field names.\r\n",
      "  --meta-analysis-a2-field <n...>    Defaults are 'CHR', 'SNP', 'BP', 'A1',\r\n",
      "  --meta-analysis-p-field <n...>     'A2', 'P', 'SE', and 'NMISS',\r\n",
      "  --meta-analysis-se-field <n...>    respectively.  When multiple parameters\r\n",
      "  --meta-analysis-ess-field <n...>   are given to these flags, earlier names\r\n",
      "                                     take precedence over later ones.\r\n",
      "                                     Note that, if the numbers of cases and\r\n",
      "                                     controls are unequal, effective sample\r\n",
      "                                     size should be\r\n",
      "                                       4 / (1/<# cases> + 1/<# controls>).\r\n",
      "  --meta-analysis-report-dups      : When a variant appears multiple times in\r\n",
      "                                     in the same file, report that.\r\n",
      "  --gene-list-border <kbs>   : Extend --gene-report regions by given # of kbs.\r\n",
      "  --gene-subset <filename>   : Specify gene name subset for --gene-report.\r\n",
      "  --gene-report-snp-field <> : Set --gene-report variant ID field name (default\r\n",
      "                               'SNP').  Only relevant with --extract.\r\n",
      "  --gap <kbs>      : Set \"--fast-epistasis case-only\" min. gap (default 1000).\r\n",
      "  --epi1 <p-value> : Set --[fast-]epistasis reporting threshold (default\r\n",
      "                     5e-6 for 'boost', 1e-4 otherwise).\r\n",
      "  --epi2 <p-value> : Set threshold for contributing to SIG_E count (def. 0.01).\r\n",
      "  --je-cellmin <n> : Set required number of observations per 3x3x2 contingency\r\n",
      "                     table cell for joint-effects test (default 5).\r\n",
      "  --q-score-range <range file> <data file> [i] [j] ['header'] :\r\n",
      "    Apply --score to subset(s) of variants in the primary score list based\r\n",
      "    on e.g. p-value ranges.\r\n",
      "    * The first file should have range labels in the first column, p-value\r\n",
      "      lower bounds in the second column, and upper bounds in the third column.\r\n",
      "      Lines with too few entries, or nonnumeric values in the second or third\r\n",
      "      column, are ignored.\r\n",
      "    * The second file should contain a variant ID and a p-value on each\r\n",
      "      nonempty line (except possibly the first).  Variant IDs are read from\r\n",
      "      column #i and p-values are read from column #j, where i defaults to 1 and\r\n",
      "      j defaults to i+1.  The 'header' modifier causes the first nonempty line\r\n",
      "      of this file to be skipped.\r\n",
      "  --R-port <port #>  : Connect to Rserve on a port other than 6311.\r\n",
      "  --R-host <host>    : Connect to Rserve host.\r\n",
      "  --R-socket <sock>  : Connect to Rserve socket.\r\n",
      "  --parallel <k> <n> : Divide the output matrix into n pieces, and only compute\r\n",
      "                       the kth piece.  The primary output file will have the\r\n",
      "                       piece number included in its name, e.g. plink.rel.13 or\r\n",
      "                       plink.rel.13.gz if k is 13.  Concatenating these files\r\n",
      "                       in order will yield the full matrix of interest.  (Yes,\r\n",
      "                       this can be done before unzipping.)\r\n",
      "                       N.B. This generally cannot be used to directly write a\r\n",
      "                       symmetric square matrix.  Choose square0 or triangle\r\n",
      "                       shape instead, and postprocess as necessary.\r\n",
      "  --memory <val>     : Set size, in MB, of initial workspace malloc attempt.\r\n",
      "                       (Practically mandatory when using GNU parallel.)\r\n",
      "  --threads <val>    : Set maximum number of concurrent threads.\r\n",
      "                       This has one known limitation: some BLAS/LAPACK linear\r\n",
      "                       algebra operations are multithreaded in a way that PLINK\r\n",
      "                       cannot control.  If this is problematic, you should\r\n",
      "                       recompile against single-threaded BLAS/LAPACK.\r\n",
      "  --d <char>         : Change variant/covariate range delimiter (normally '-').\r\n",
      "  --seed <val...>    : Set random number seed(s).  Each value must be an\r\n",
      "                       integer between 0 and 4294967295 inclusive.\r\n",
      "  --perm-batch-size <val> : Set number of permutations per batch for some\r\n",
      "                            permutation tests.\r\n",
      "  --native           : Allow Intel MKL to use processor-dependent code paths.\r\n",
      "  --output-min-p <p> : Specify minimum p-value to write to reports.\r\n",
      "  --debug            : Use slower, more crash-resistant logging method.\r\n",
      "\r\n",
      "Primary methods paper:\r\n",
      "Chang CC, Chow CC, Tellier LCAM, Vattikuti S, Purcell SM, Lee JJ (2015)\r\n",
      "Second-generation PLINK: rising to the challenge of larger and richer datasets.\r\n",
      "GigaScience, 4.\r\n",
      "\r\n",
      "For further documentation and support, consult the main webpage\r\n",
      "(https://www.cog-genomics.org/plink/1.9 ) and/or the mailing list\r\n",
      "(https://groups.google.com/d/forum/plink2-users ).\r\n"
     ]
    }
   ],
   "source": [
    "! plink --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8022f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ed9ac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/snps_clean.log.\n",
      "Options in effect:\n",
      "  --23file raw_data/ManuSporny-genome.txt\n",
      "  --out data/snps_clean\n",
      "  --output-chr MT\n",
      "  --recode vcf\n",
      "  --snps-only just-acgt\n",
      "\n",
      "15778 MB RAM detected; reserving 7889 MB for main workspace.\n",
      "--23file: data/snps_clean-temporary.bed + data/snps_clean-temporary.bim +\n",
      "data/snps_clean-temporary.fam written.\n",
      "1090 variants with indel calls present.  '--snps-only no-DI' or\n",
      "--list-23-indels may be useful here.\n",
      "Inferred sex: male.\n",
      "965887 out of 966977 variants loaded from .bim file.\n",
      "1 person (1 male, 0 females) loaded from .fam.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 1 founder and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 114 het. haploid genotypes present (see data/snps_clean.hh ); many\n",
      "commands treat these as missing.\n",
      "Total genotyping rate is 0.993452.\n",
      "965887 variants and 1 person pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--recode vcf to data/snps_clean.vcf ... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n"
     ]
    }
   ],
   "source": [
    "! plink --23file raw_data/ManuSporny-genome.txt --recode vcf --out data/snps_clean --output-chr MT --snps-only just-acgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d93288b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/snps_clean_MikeRaiko.log.\n",
      "Options in effect:\n",
      "  --23file raw_data/MikeRaiko-genome.txt\n",
      "  --out data/snps_clean_MikeRaiko\n",
      "  --output-chr MT\n",
      "  --recode vcf\n",
      "  --snps-only just-acgt\n",
      "\n",
      "15778 MB RAM detected; reserving 7889 MB for main workspace.\n",
      "--23file: data/snps_clean_MikeRaiko-temporary.bed +\n",
      "data/snps_clean_MikeRaiko-temporary.bim +\n",
      "data/snps_clean_MikeRaiko-temporary.fam written.\n",
      "15125 variants with indel calls present.  '--snps-only no-DI' or\n",
      "--list-23-indels may be useful here.\n",
      "Inferred sex: male.\n",
      "595401 out of 610526 variants loaded from .bim file.\n",
      "1 person (1 male, 0 females) loaded from .fam.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 1 founder and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 103 het. haploid genotypes present (see data/snps_clean_MikeRaiko.hh\n",
      "); many commands treat these as missing.\n",
      "Total genotyping rate is 0.989246.\n",
      "595401 variants and 1 person pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--recode vcf to data/snps_clean_MikeRaiko.vcf ... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n"
     ]
    }
   ],
   "source": [
    "! plink --23file raw_data/MikeRaiko-genome.txt --recode vcf --out data/snps_clean_MikeRaiko --output-chr MT --snps-only just-acgt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9165d4",
   "metadata": {},
   "source": [
    "## Origins, haplogroups\n",
    "\n",
    "Establish probable ethnicity of given subject by identifying maternal (mtDNA) and paternal (Y chromosome) haplogroups.\n",
    "\n",
    "https://dna.jameslick.com/mthap/ - shows all SNPs that distinguish the haplogroup, and takes 23andMe input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78658ed3",
   "metadata": {},
   "source": [
    "### Mike Raiko:\n",
    "\n",
    "\n",
    "mthap version 0.19b (2015-05-11); haplogroup data version PhyloTree Build 17 (2016-02-18) +mods\n",
    "raw data source MikeRaiko-genome.txt (14MB)\n",
    "\n",
    "Found 3270 markers at 3268 positions covering 19.7% of mtDNA.\n",
    "\n",
    "Markers found (shown as differences to rCRS):\n",
    "\n",
    "HVR2: 152C 263G\n",
    "CR: 750G 1438G 4769G 8860G\n",
    "HVR1:\n",
    "\n",
    "IMPORTANT NOTE: The above marker list is almost certainly incomplete due to limitations of genotyping technology and is not comparable to mtDNA sequencing results. It should not be used with services or tools that expect sequencing results, such as mitosearch.\n",
    "\n",
    "Best mtDNA Haplogroup Matches:\n",
    "\n",
    "1) H(T152C)\n",
    "\n",
    "Defining Markers for haplogroup H(T152C):\n",
    "HVR2: 152C 263G\n",
    "CR: 750G 1438G 4769G 8860G 15326G\n",
    "HVR1:\n",
    "\n",
    "Marker path from rCRS to haplogroup H(T152C):\n",
    "H2a2a1(rCRS) ⇨ 263G ⇨ H2a2a ⇨ 8860G 15326G ⇨ H2a2 ⇨ 750G ⇨ H2a ⇨ 4769G ⇨ H2 ⇨ 1438G ⇨ H ⇨ 152C ⇨ H(T152C)\n",
    "\n",
    "Imperfect Match. Your results contained differences with this haplogroup:\n",
    "Matches(6): 152C 263G 750G 1438G 4769G 8860G\n",
    "Untested(1): 15326\n",
    "\n",
    "2) H1(T152C)\n",
    "\n",
    "Defining Markers for haplogroup H1(T152C):\n",
    "HVR2: 152C 263G\n",
    "CR: 750G 1438G 3010A 4769G 8860G 15326G\n",
    "HVR1:\n",
    "\n",
    "Marker path from rCRS to haplogroup H1(T152C):\n",
    "H2a2a1(rCRS) ⇨ 263G ⇨ H2a2a ⇨ 8860G 15326G ⇨ H2a2 ⇨ 750G ⇨ H2a ⇨ 4769G ⇨ H2 ⇨ 1438G ⇨ H ⇨ 3010A ⇨ H1 ⇨ 152C ⇨ H1(T152C)\n",
    "\n",
    "Imperfect Match. Your results contained differences with this haplogroup:\n",
    "Matches(6): 152C 263G 750G 1438G 4769G 8860G\n",
    "No-Calls(1): 3010A\n",
    "Untested(1): 15326\n",
    "\n",
    "3) H\n",
    "\n",
    "Defining Markers for haplogroup H:\n",
    "HVR2: 263G\n",
    "CR: 750G 1438G 4769G 8860G 15326G\n",
    "HVR1:\n",
    "\n",
    "Marker path from rCRS to haplogroup H (plus extra markers):\n",
    "H2a2a1(rCRS) ⇨ 263G ⇨ H2a2a ⇨ 8860G 15326G ⇨ H2a2 ⇨ 750G ⇨ H2a ⇨ 4769G ⇨ H2 ⇨ 1438G ⇨ H ⇨ 152C\n",
    "\n",
    "Imperfect Match. Your results contained differences with this haplogroup:\n",
    "Matches(5): 263G 750G 1438G 4769G 8860G\n",
    "Extras(1): 152C\n",
    "Untested(1): 15326\n",
    "\n",
    "3) H9\n",
    "\n",
    "Defining Markers for haplogroup H9:\n",
    "HVR2: 152C 263G\n",
    "CR: 750G 1438G 4769G 8860G 13020C 15326G\n",
    "HVR1:\n",
    "\n",
    "Marker path from rCRS to haplogroup H9:\n",
    "H2a2a1(rCRS) ⇨ 263G ⇨ H2a2a ⇨ 8860G 15326G ⇨ H2a2 ⇨ 750G ⇨ H2a ⇨ 4769G ⇨ H2 ⇨ 1438G ⇨ H ⇨ 152C ⇨ H(T152C) ⇨ 13020C ⇨ H9\n",
    "\n",
    "Imperfect Match. Your results contained differences with this haplogroup:\n",
    "Matches(6): 152C 263G 750G 1438G 4769G 8860G\n",
    "Mismatches(1): 13020T\n",
    "Untested(1): 15326\n",
    "\n",
    "3) H46\n",
    "\n",
    "Defining Markers for haplogroup H46:\n",
    "HVR2: 152C 263G\n",
    "CR: 750G 1438G 2772T 4769G 8860G 15326G\n",
    "HVR1:\n",
    "\n",
    "Marker path from rCRS to haplogroup H46:\n",
    "H2a2a1(rCRS) ⇨ 263G ⇨ H2a2a ⇨ 8860G 15326G ⇨ H2a2 ⇨ 750G ⇨ H2a ⇨ 4769G ⇨ H2 ⇨ 1438G ⇨ H ⇨ 152C ⇨ H(T152C) ⇨ 2772T ⇨ H46\n",
    "\n",
    "Imperfect Match. Your results contained differences with this haplogroup:\n",
    "Matches(6): 152C 263G 750G 1438G 4769G 8860G\n",
    "Mismatches(1): 2772C\n",
    "Untested(1): 15326\n",
    "\n",
    "3) H3(T152C)\n",
    "\n",
    "Defining Markers for haplogroup H3(T152C):\n",
    "HVR2: 152C 263G\n",
    "CR: 750G 1438G 4769G 6776C 8860G 15326G\n",
    "HVR1:\n",
    "\n",
    "Marker path from rCRS to haplogroup H3(T152C):\n",
    "H2a2a1(rCRS) ⇨ 263G ⇨ H2a2a ⇨ 8860G 15326G ⇨ H2a2 ⇨ 750G ⇨ H2a ⇨ 4769G ⇨ H2 ⇨ 1438G ⇨ H ⇨ 6776C ⇨ H3 ⇨ 152C ⇨ H3(T152C)\n",
    "\n",
    "Imperfect Match. Your results contained differences with this haplogroup:\n",
    "Matches(6): 152C 263G 750G 1438G 4769G 8860G\n",
    "Mismatches(1): 6776T\n",
    "Untested(1): 15326\n",
    "\n",
    "3) H52\n",
    "\n",
    "Defining Markers for haplogroup H52:\n",
    "HVR2: 152C 263G\n",
    "CR: 750G 1438G 4769G 8860G 14220G 15326G\n",
    "HVR1:\n",
    "\n",
    "Marker path from rCRS to haplogroup H52:\n",
    "H2a2a1(rCRS) ⇨ 263G ⇨ H2a2a ⇨ 8860G 15326G ⇨ H2a2 ⇨ 750G ⇨ H2a ⇨ 4769G ⇨ H2 ⇨ 1438G ⇨ H ⇨ 152C ⇨ H(T152C) ⇨ 14220G ⇨ H52\n",
    "\n",
    "Imperfect Match. Your results contained differences with this haplogroup:\n",
    "Matches(6): 152C 263G 750G 1438G 4769G 8860G\n",
    "Mismatches(1): 14220A\n",
    "Untested(1): 15326\n",
    "\n",
    "3) H16(T152C)\n",
    "\n",
    "Defining Markers for haplogroup H16(T152C):\n",
    "HVR2: 152C 263G\n",
    "CR: 750G 1438G 4769G 8860G 10394T 15326G\n",
    "HVR1:\n",
    "\n",
    "Marker path from rCRS to haplogroup H16(T152C):\n",
    "H2a2a1(rCRS) ⇨ 263G ⇨ H2a2a ⇨ 8860G 15326G ⇨ H2a2 ⇨ 750G ⇨ H2a ⇨ 4769G ⇨ H2 ⇨ 1438G ⇨ H ⇨ 10394T ⇨ H16 ⇨ 152C ⇨ H16(T152C)\n",
    "\n",
    "Imperfect Match. Your results contained differences with this haplogroup:\n",
    "Matches(6): 152C 263G 750G 1438G 4769G 8860G\n",
    "Mismatches(1): 10394C\n",
    "Untested(1): 15326\n",
    "\n",
    "3) H69\n",
    "\n",
    "Defining Markers for haplogroup H69:\n",
    "HVR2: 152C 263G\n",
    "CR: 750G 1438G 4646C 4769G 8860G 15326G\n",
    "HVR1:\n",
    "\n",
    "Marker path from rCRS to haplogroup H69:\n",
    "H2a2a1(rCRS) ⇨ 263G ⇨ H2a2a ⇨ 8860G 15326G ⇨ H2a2 ⇨ 750G ⇨ H2a ⇨ 4769G ⇨ H2 ⇨ 1438G ⇨ H ⇨ 152C ⇨ H(T152C) ⇨ 4646C ⇨ H69\n",
    "\n",
    "Imperfect Match. Your results contained differences with this haplogroup:\n",
    "Matches(6): 152C 263G 750G 1438G 4769G 8860G\n",
    "Mismatches(1): 4646T\n",
    "Untested(1): 15326 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b52cd",
   "metadata": {},
   "source": [
    "## Annotation - sex and eye colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b4bed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs12913832\t15\t28365618\tAG\n",
      "rs12203592\t6\t396321\tCT\n",
      "rs16891982\t5\t33951693\tCG\n",
      "rs12896399\t14\t92773663\tGG\n",
      "rs1426654\t15\t48426484\tAA\n",
      "rs885479\t16\t89986154\tGG\n"
     ]
    }
   ],
   "source": [
    "eye_skin_colour_rsids = [\"rs12913832\",\n",
    "                         \"rs12203592\",\n",
    "                         \"rs16891982\",\n",
    "                         \"rs6119471\",\n",
    "                         \"rs12896399\",\n",
    "                         \"rs1426654\",\n",
    "                         \"rs1545397\",\n",
    "                         \"rs885479\",\n",
    "                        ]\n",
    "\n",
    "find_snps_by_rsid(\"raw_data/MikeRaiko-genome.txt\", eye_skin_colour_rsids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8a95b",
   "metadata": {},
   "source": [
    "Eye colour: Brown\n",
    "Skin colour: light or medium (not dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df186c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs12913832\t15\t26039213\tAG\n",
      "rs12203592\t6\t341321\tCC\n",
      "rs16891982\t5\t33987450\tCG\n",
      "rs12896399\t14\t91843416\tGT\n",
      "rs1426654\t15\t46213776\tAG\n",
      "rs885479\t16\t88513655\tGG\n"
     ]
    }
   ],
   "source": [
    "find_snps_by_rsid(\"raw_data/ManuSporny-genome.txt\", eye_skin_colour_rsids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd646145",
   "metadata": {},
   "source": [
    "## Annotation of all SNPs, selection of clinically relevant ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5811be86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:00 SnpEff version SnpEff 5.1d (build 2022-04-19 15:49), by Pablo Cingolani\n",
      "00:00:00 Command: 'download'\n",
      "00:00:00 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75'\n",
      "00:00:00 Reading config file: /home/nikitos/Bioinformatics/BI/Workshop_on_bioinformatics/Project5/snpEff.config\n",
      "00:00:00 Reading config file: /home/nikitos/Programs/anaconda3/envs/bio/share/snpeff-5.1-2/snpEff.config\n",
      "00:00:00 done\n",
      "00:00:00 Downloading database for 'GRCh37.75'\n",
      "00:00:00 Downloading from 'https://snpeff.blob.core.windows.net/databases/v5_1/snpEff_v5_1_GRCh37.75.zip' to local file '/tmp/snpEff_v5_1_GRCh37.75.zip'\n",
      "00:00:00 Connecting to https://snpeff.blob.core.windows.net/databases/v5_1/snpEff_v5_1_GRCh37.75.zip\n",
      "00:00:00 Connecting to https://snpeff.blob.core.windows.net/databases/v5_1/snpEff_v5_1_GRCh37.75.zip, using proxy: false\n",
      "00:00:02 ERROR while connecting to https://snpeff.blob.core.windows.net/databases/v5_1/snpEff_v5_1_GRCh37.75.zip\n",
      "00:00:02 Downloading from 'https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_GRCh37.75.zip' to local file '/tmp/snpEff_v5_0_GRCh37.75.zip'\n",
      "00:00:02 Connecting to https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_GRCh37.75.zip\n",
      "00:00:02 Connecting to https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_GRCh37.75.zip, using proxy: false\n",
      "00:00:03 Local file name: '/tmp/snpEff_v5_0_GRCh37.75.zip'\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................00:10:37 \n",
      "00:10:37 Download finished. Total 563180888 bytes.\n",
      "00:10:37 Extracting file 'data/GRCh37.75/pwms.bin'\n",
      "00:10:37 Creating local directory: '/home/nikitos/Programs/anaconda3/envs/bio/share/snpeff-5.1-2/./data/GRCh37.75'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.1.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.10.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.11.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.12.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.13.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.14.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.15.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.16.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.17.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.18.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.19.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.2.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.20.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.21.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.22.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.3.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.4.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.5.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.6.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.7.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.8.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.9.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HG1091_PATCH.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HG1257_PATCH.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HG1287_PATCH.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HG1424_PATCH.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HG1433_PATCH.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HG1436_HG1432_PATCH.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HG1459_PATCH.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HG1497_PATCH.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HG375_PATCH.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HSCHR5_1_CTG1.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HSCHR6_MHC_APD.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HSCHR6_MHC_COX.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HSCHR6_MHC_DBB.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HSCHR6_MHC_MANN.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HSCHR6_MHC_MCF.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HSCHR6_MHC_QBL.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.HSCHR6_MHC_SSTO.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.X.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.Y.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/sequence.bin'\n",
      "00:10:37 Extracting file 'data/GRCh37.75/snpEffectPredictor.bin'\n",
      "00:10:38 Extracting file 'data/GRCh37.75/cytoBand.txt.gz'\n",
      "00:10:38 Unzip: OK\n",
      "00:10:38 Deleted local file '/tmp/snpEff_v5_0_GRCh37.75.zip'\n",
      "00:10:38 Done\n",
      "00:10:38 Logging\n",
      "00:10:40 Done.\n"
     ]
    }
   ],
   "source": [
    "! snpEff download -v GRCh37.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95720dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\r\n"
     ]
    }
   ],
   "source": [
    "! snpEff GRCh37.75 data/snps_clean_MikeRaiko.vcf > snps_snpeff_MikeRaiko.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d5ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608feb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab2f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
